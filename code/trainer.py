"""
trainer.py: è®­ç»ƒå¾ªç¯ä¸æ—¥å¿—ç³»ç»Ÿ

ã€ç¬¬å…­é˜¶æ®µã€‘è®­ç»ƒå¾ªç¯ä¸æ—¥å¿—ç³»ç»Ÿ (Training Loop & Operations)

ã€æ ¸å¿ƒç†å¿µã€‘

è¿™ä¸ä»…æ˜¯ç®€å•çš„ for å¾ªç¯ï¼Œè€Œæ˜¯æ„å»ºä¸€ä¸ªå¯ç›‘æ§ã€å¯ä¸­æ–­ã€å¯æ¢å¤çš„è®­ç»ƒå¼•æ“ã€‚
å…³é”®ç‰¹æ€§ï¼š

1. å¥å£®çš„è®­ç»ƒå·¥ç¨‹
   âœ“ æ¨¡å—åŒ–æ¶æ„ï¼šé‡å¤è°ƒç”¨ä»£ç å°è£…ä¸ºç±»
   âœ“ å®Œæ•´çš„é”™è¯¯å¤„ç†å’Œæ¢å¤æœºåˆ¶
   âœ“ è¯¦ç»†çš„è®­ç»ƒæ—¥å¿—å’ŒæŒ‡æ ‡å¯è§†åŒ–
   âœ“ ä¸­æ–­æ¢å¤ï¼šæ”¯æŒ checkpoint ä¿å­˜å’ŒåŠ è½½
   âœ“ æ—©åœæœºåˆ¶ï¼šéªŒè¯é›†æŒ‡æ ‡ä¸ä¸Šå‡æ—¶åœæ­¢è®­ç»ƒ

2. æŸå¤±å‡½æ•°è®¾è®¡
   âœ“ ç±»åˆ«ä¸å¹³è¡¡å¤„ç†ï¼šè‡ªåŠ¨è®¡ç®— class_weights
   âœ“ æ©è†œæŸå¤±ï¼šä»…å¯¹ä¸­å¿ƒåƒç´ è®¡ç®—æ¢¯åº¦
   âœ“ å¯é€‰çš„ç„¦ç‚¹æŸå¤±ï¼ˆFocal Lossï¼‰åº”å¯¹æç«¯ä¸å¹³è¡¡

3. éªŒè¯åè®®
   âœ“ å¤šæŒ‡æ ‡è¯„ä¼°ï¼šAccuracy, Precision, Recall, F1-Score, IoU
   âœ“ Debug æ¨¡å¼ï¼šåœ¨å°æ ·æœ¬ä¸Šå¿«é€Ÿè¿‡æ‹Ÿåˆæµ‹è¯•
   âœ“ è¯¦ç»†çš„éªŒè¯æŠ¥å‘Šå’Œæ··æ·†çŸ©é˜µ

ã€æ¶æ„è®¾è®¡ã€‘

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Trainer ç±»                                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  åˆå§‹åŒ–ï¼š                                                    â”‚
â”‚  - æ¨¡å‹ã€ä¼˜åŒ–å™¨ã€æŸå¤±å‡½æ•°ã€è®¾å¤‡                              â”‚
â”‚  - éªŒè¯/æµ‹è¯•é›†ã€æŒ‡æ ‡è®¡ç®—å™¨                                   â”‚
â”‚  - æ—¥å¿—è®°å½•å™¨                                                â”‚
â”‚                                                              â”‚
â”‚  æ ¸å¿ƒæ–¹æ³•ï¼š                                                  â”‚
â”‚  1. train_epoch()       â†’ æ‰§è¡Œä¸€ä¸ª epoch çš„è®­ç»ƒ              â”‚
â”‚  2. validate()          â†’ åœ¨éªŒè¯é›†ä¸Šè¯„ä¼°                     â”‚
â”‚  3. train()             â†’ å®Œæ•´çš„è®­ç»ƒå¾ªç¯                     â”‚
â”‚  4. save_checkpoint()   â†’ ä¿å­˜æ¨¡å‹æƒé‡                       â”‚
â”‚  5. load_checkpoint()   â†’ åŠ è½½æ¨¡å‹æƒé‡                       â”‚
â”‚  6. compute_class_weights() â†’ è®¡ç®—ç±»åˆ«æƒé‡                   â”‚
â”‚                                                              â”‚
â”‚  è¾…åŠ©ç»„ä»¶ï¼š                                                  â”‚
â”‚  - MaskedCrossEntropyLoss:  æ©è†œæŸå¤±å‡½æ•°                     â”‚
â”‚  - MetricsCalculator:       æŒ‡æ ‡è®¡ç®—å™¨                       â”‚
â”‚  - TrainingLogger:          è®­ç»ƒæ—¥å¿—                         â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
"""

import json
import logging
import sys
import time
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Any, Union
from datetime import datetime
from collections import defaultdict

import numpy as np
import pandas as pd  # å¼•å…¥ pandas ç”¨äºè¾“å‡º CSV
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import DataLoader
from tqdm import tqdm
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    confusion_matrix, classification_report
)


# ============================================================================
# æ—¥å¿—è®°å½•å™¨
# ============================================================================

class TrainingLogger:
    """è®­ç»ƒæ—¥å¿—è®°å½•å™¨"""
    
    def __init__(self, output_dir: Path, verbose: bool = True):
        """
        åˆå§‹åŒ–æ—¥å¿—è®°å½•å™¨
        
        Args:
            output_dir: è¾“å‡ºç›®å½•
            verbose: æ˜¯å¦æ‰“å°åˆ°æ§åˆ¶å°
        """
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.verbose = verbose
        
        self.log_file = self.output_dir / 'training_log.txt'
        self.metrics_file = self.output_dir / 'training_metrics.json'
        
        self.metrics_history = {
            'train_loss': [],
            'train_accuracy': [],
            'train_f1_macro': [],
            'train_f1_weighted': [],
            'val_loss': [],
            'val_accuracy': [],
            'val_f1_macro': [],
            'val_f1_weighted': [],
            'val_iou': [],
        }
        
        self._setup_logging()
    
    @staticmethod
    def _setup_logging():
        """é…ç½®æ—¥å¿—ç³»ç»Ÿ"""
        if not logging.getLogger(__name__).handlers:
            handler = logging.StreamHandler(sys.stdout)
            formatter = logging.Formatter(
                '%(levelname)s: %(message)s'
            )
            handler.setFormatter(formatter)
            logging.getLogger(__name__).addHandler(handler)
            logging.getLogger(__name__).setLevel(logging.INFO)
    
    def log(self, message: str, level: str = 'INFO'):
        """
        è®°å½•æ—¥å¿—
        
        Args:
            message: æ—¥å¿—æ¶ˆæ¯
            level: æ—¥å¿—çº§åˆ«
        """
        logger = logging.getLogger(__name__)
        
        if level == 'INFO':
            logger.info(message)
        elif level == 'WARNING':
            logger.warning(message)
        elif level == 'ERROR':
            logger.error(message)
        elif level == 'DEBUG':
            logger.debug(message)
        
        # å†™å…¥æ–‡ä»¶
        with open(self.log_file, 'a', encoding='utf-8') as f:
            timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            f.write(f"[{timestamp}] {level}: {message}\n")
    
    def log_metrics(self, epoch: int, metrics: Dict[str, float]):
        """è®°å½•æŒ‡æ ‡"""
        for key, value in metrics.items():
            if key in self.metrics_history:
                self.metrics_history[key].append(value)
    
    def save_metrics(self):
        """ä¿å­˜æŒ‡æ ‡åˆ° JSON æ–‡ä»¶"""
        with open(self.metrics_file, 'w', encoding='utf-8') as f:
            json.dump(self.metrics_history, f, indent=2)
    
    def print_header(self, title: str):
        """æ‰“å°æ ‡é¢˜"""
        if self.verbose:
            line = "=" * 80
            print(f"\n{line}")
            print(f"ğŸš€ {title}")
            print(f"{line}\n")
        self.log(f"\n{'=' * 80}")
        self.log(title)
        self.log(f"{'=' * 80}")
    
    def print_epoch_summary(self, epoch: int, num_epochs: int, metrics: Dict[str, float], is_best: bool = False):
        """æ‰“å° epoch æ‘˜è¦"""
        best_marker = " (â†‘ best)" if is_best else ""
        
        # âœ¨ æ ¹æ®å¯ç”¨çš„æŒ‡æ ‡åˆ¤æ–­åˆ†å±‚è¿˜æ˜¯æ ‡å‡†æ¨¡å¼
        if 'train_hierarchical_accuracy' in metrics:
            # åˆ†å±‚æ¨¡å¼
            train_loss = metrics.get('train_loss', 0)
            train_major_acc = metrics.get('train_major_accuracy', 0)
            train_detail_acc = metrics.get('train_detail_accuracy', 0)
            train_hier_acc = metrics.get('train_hierarchical_accuracy', 0)
            
            val_loss = metrics.get('val_loss', 0)
            val_major_acc = metrics.get('val_major_accuracy', 0)
            val_detail_acc = metrics.get('val_detail_accuracy', 0)
            val_hier_acc = metrics.get('val_hierarchical_accuracy', 0)
            
            message = (
                f"Epoch {epoch}/{num_epochs}: "
                f"Train Loss={train_loss:.4f} "
                f"Major={train_major_acc:.1%} Detail={train_detail_acc:.1%} Hier={train_hier_acc:.1%} | "
                f"Val Loss={val_loss:.4f} "
                f"Major={val_major_acc:.1%} Detail={val_detail_acc:.1%} Hier={val_hier_acc:.1%}{best_marker}"
            )
        else:
            # æ ‡å‡†æ¨¡å¼
            train_loss = metrics.get('train_loss', 0)
            train_acc = metrics.get('train_accuracy', 0)
            train_f1 = metrics.get('train_f1_macro', 0)
            
            val_loss = metrics.get('val_loss', 0)
            val_acc = metrics.get('val_accuracy', 0)
            val_f1 = metrics.get('val_f1_macro', 0)
            
            message = (
                f"Epoch {epoch}/{num_epochs}: "
                f"Train Loss={train_loss:.4f} Acc={train_acc:.1%} F1={train_f1:.4f} | "
                f"Val Loss={val_loss:.4f} Acc={val_acc:.1%} F1={val_f1:.4f}{best_marker}"
            )
        
        if self.verbose:
            print(message)
        
        self.log(message)


# ============================================================================
# æŒ‡æ ‡è®¡ç®—å™¨
# ============================================================================

class MetricsCalculator:
    """æŒ‡æ ‡è®¡ç®—å™¨"""
    
    @staticmethod
    def compute_metrics(
        predictions: np.ndarray,
        targets: np.ndarray,
        num_classes: int,
        average_methods: List[str] = None,
    ) -> Dict[str, float]:
        """
        è®¡ç®—åˆ†ç±»æŒ‡æ ‡
        
        Args:
            predictions: é¢„æµ‹æ ‡ç­¾ (N,)
            targets: çœŸå®æ ‡ç­¾ (N,)
            num_classes: ç±»åˆ«æ€»æ•°
            average_methods: å¹³å‡æ–¹æ³•åˆ—è¡¨ ['macro', 'weighted']
        
        Returns:
            åŒ…å«å„é¡¹æŒ‡æ ‡çš„å­—å…¸
        """
        if average_methods is None:
            average_methods = ['macro', 'weighted']
        
        metrics = {
            'accuracy': float(accuracy_score(targets, predictions)),
        }
        
        # F1-Scoreï¼ˆå¤šç§å¹³å‡æ–¹å¼ï¼‰
        for avg_method in average_methods:
            key = f'f1_{avg_method}'
            try:
                metrics[key] = float(f1_score(targets, predictions, average=avg_method, zero_division=0))
            except:
                metrics[key] = 0.0
        
        # Precision å’Œ Recall
        try:
            metrics['precision'] = float(precision_score(targets, predictions, average='weighted', zero_division=0))
            metrics['recall'] = float(recall_score(targets, predictions, average='weighted', zero_division=0))
        except:
            metrics['precision'] = 0.0
            metrics['recall'] = 0.0
        
        # IoU (Intersection over Union)
        metrics['iou'] = MetricsCalculator.compute_iou(predictions, targets, num_classes)
        
        return metrics
    
    @staticmethod
    def compute_iou(predictions: np.ndarray, targets: np.ndarray, num_classes: int) -> float:
        """
        è®¡ç®— IoU (Intersection over Union)
        
        IoU = TP / (TP + FP + FN)
        
        Args:
            predictions: é¢„æµ‹æ ‡ç­¾ (N,)
            targets: çœŸå®æ ‡ç­¾ (N,)
            num_classes: ç±»åˆ«æ€»æ•°
        
        Returns:
            å¹³å‡ IoU
        """
        iou_list = []
        
        for class_id in range(num_classes):
            tp = np.sum((predictions == class_id) & (targets == class_id))
            fp = np.sum((predictions == class_id) & (targets != class_id))
            fn = np.sum((predictions != class_id) & (targets == class_id))
            
            denominator = tp + fp + fn
            if denominator > 0:
                iou = tp / denominator
                iou_list.append(iou)
        
        if iou_list:
            return float(np.mean(iou_list))
        else:
            return 0.0
    
    @staticmethod
    def compute_confusion_matrix(predictions: np.ndarray, targets: np.ndarray) -> np.ndarray:
        """è®¡ç®—æ··æ·†çŸ©é˜µ"""
        return confusion_matrix(targets, predictions)


# ============================================================================
# æŸå¤±å‡½æ•°
# ============================================================================

class WeightedCrossEntropyLoss(nn.Module):
    """
    åŠ æƒäº¤å‰ç†µæŸå¤±
    
    ç”¨äºå¤„ç†ç±»åˆ«ä¸å¹³è¡¡é—®é¢˜ã€‚æ ¹æ®ç±»åˆ«é¢‘ç‡è‡ªåŠ¨è®¡ç®—æƒé‡ã€‚
    """
    
    def __init__(
        self,
        weight: Optional[torch.Tensor] = None,
        reduction: str = 'mean',
    ):
        """
        åˆå§‹åŒ–åŠ æƒäº¤å‰ç†µæŸå¤±
        
        Args:
            weight: ç±»åˆ«æƒé‡
            reduction: å½’çº¦æ–¹å¼
        """
        super().__init__()
        self.ce_loss = nn.CrossEntropyLoss(
            weight=weight,
            reduction=reduction,
        )
    
    def forward(self, logits: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:
        """è®¡ç®—æŸå¤±"""
        return self.ce_loss(logits, targets)


# ============================================================================
# è®­ç»ƒå™¨ç±»
# ============================================================================

class Trainer:
    """
    è®­ç»ƒå™¨ç±»
    """
    
    def __init__(
        self,
        model: nn.Module,
        train_dataloader: DataLoader,
        val_dataloader: Optional[DataLoader] = None,
        test_dataloader: Optional[DataLoader] = None,
        num_classes: Optional[int] = None,
        hierarchical_map: Optional[dict] = None,
        device: str = 'cuda',
        output_dir: Optional[Path] = None,
        verbose: bool = True,
    ):
        """
        åˆå§‹åŒ–è®­ç»ƒå™¨
        """
        self.model = model
        self.train_dataloader = train_dataloader
        self.val_dataloader = val_dataloader
        self.test_dataloader = test_dataloader
        self.hierarchical_map = hierarchical_map
        self.device = torch.device(device)
        self.verbose = verbose
        
        # ç¡®å®šnum_classes
        if hierarchical_map is not None:
            # ä½¿ç”¨åˆ†å±‚æ˜ å°„è®¡ç®—æ€»å°ç±»æ•°
            self.num_classes = sum(
                len(info.get('detail_classes', {})) 
                for info in hierarchical_map.values()
            )
            self.is_hierarchical = True
        else:
            # ä½¿ç”¨ä¼ å…¥çš„ num_classes
            self.num_classes = num_classes if num_classes is not None else 8
            self.is_hierarchical = False
        
        # è®¾ç½®è¾“å‡ºç›®å½•
        if output_dir is None:
            output_dir = Path('./experiments/outputs')
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # åˆå§‹åŒ–æ—¥å¿—
        self.logger = TrainingLogger(self.output_dir, verbose=verbose)
        
        # è®¾å¤‡æ£€æŸ¥
        self.logger.log(f"ä½¿ç”¨è®¾å¤‡: {self.device}")
        if self.device.type == 'cuda':
            self.logger.log(f"GPU å‹å·: {torch.cuda.get_device_name()}")
        
        # æ‰“å°åˆ†ç±»æ¨¡å¼
        if self.is_hierarchical:
            self.logger.log(f"ä½¿ç”¨åˆ†å±‚åˆ†ç±»æ¨¡å¼ï¼š{len(hierarchical_map)} ä¸ªå¤§ç±»ï¼Œå…± {self.num_classes} ä¸ªå°ç±»")
        else:
            self.logger.log(f"ä½¿ç”¨æ ‡å‡†åˆ†ç±»æ¨¡å¼ï¼š{self.num_classes} ä¸ªç±»åˆ«")
        
        # æ¨¡å‹æ”¾åˆ°è®¾å¤‡
        self.model = self.model.to(self.device)
        
        # è®¡ç®—ç±»åˆ«æƒé‡
        if self.is_hierarchical:
            self.major_class_weights, self.detail_class_weights = self._compute_class_weights()
            
            # æ„å»º ID åˆ°åç§°çš„æ˜ å°„ï¼Œç”¨äº CSV è¾“å‡º
            self.major_id_to_name = {}
            self.detail_id_to_name = {}
            if self.hierarchical_map:
                # 1. å¤§ç±» ID -> Name
                self.major_id_to_name = {
                    info['major_id']: name 
                    for name, info in self.hierarchical_map.items()
                }
                # 2. å°ç±» ID -> Name
                for major_name, info in self.hierarchical_map.items():
                    for detail_name, detail_id in info['detail_classes'].items():
                        self.detail_id_to_name[detail_id] = detail_name
            self.logger.log("å·²æ„å»ºç±»åˆ«åç§°æ˜ å°„è¡¨ (ID -> Name)")
            
        else:
            self.class_weights = self._compute_class_weights()
        
        # åˆå§‹åŒ–ä¼˜åŒ–å™¨å’ŒæŸå¤±å‡½æ•°ï¼ˆå»¶ååˆ° train æ–¹æ³•ï¼‰
        self.optimizer = None
        self.criterion = None
        self.criterion_major = None
        self.criterion_detail = None
        
        # è®­ç»ƒå†å²åˆå§‹åŒ–
        if self.is_hierarchical:
            self.history = {
                'train_loss': [],
                'train_major_loss': [],
                'train_detail_loss': [],
                'train_major_accuracy': [],
                'train_detail_accuracy': [],
                'train_hierarchical_accuracy': [],
                'val_loss': [],
                'val_major_loss': [],
                'val_detail_loss': [],
                'val_major_accuracy': [],
                'val_detail_accuracy': [],
                'val_hierarchical_accuracy': [],
            }
        else:
            self.history = {
                'train_loss': [],
                'train_accuracy': [],
                'train_f1_macro': [],
                'train_f1_weighted': [],
                'val_loss': [],
                'val_accuracy': [],
                'val_f1_macro': [],
                'val_f1_weighted': [],
                'val_iou': [],
            }
        
        # æœ€ä½³æ¨¡å‹è¿½è¸ª
        self.best_val_f1 = -np.inf
        self.best_epoch = 0
        self.patience_counter = 0
    
    def _compute_class_weights(self) -> Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]:
        """
        è®¡ç®—ç±»åˆ«æƒé‡ä»¥å¤„ç†ç±»åˆ«ä¸å¹³è¡¡
        å¦‚æœæ˜¯åˆ†å±‚æ¨¡å¼ï¼Œè¿”å› (major_weights, detail_weights)
        """
        self.logger.log("[æƒé‡è®¡ç®—] è®¡ç®—ç±»åˆ«æƒé‡...")
        
        if self.is_hierarchical:
            # ====== åˆ†å±‚æ¨¡å¼æƒé‡è®¡ç®— ======
            num_major = len(self.hierarchical_map)
            num_detail = self.num_classes
            
            major_counts = np.zeros(num_major)
            detail_counts = np.zeros(num_detail)
            total_samples = 0
            
            for batch in tqdm(self.train_dataloader, desc="ç»Ÿè®¡ç±»åˆ«åˆ†å¸ƒ", disable=not self.verbose, leave=False):
                if isinstance(batch, dict):
                    m_labels = batch['major_label'].cpu().numpy()
                    d_labels = batch['detail_label'].cpu().numpy()
                    for l in m_labels: major_counts[l] += 1
                    for l in d_labels: detail_counts[l] += 1
                    total_samples += len(m_labels)
                else:
                    self.logger.log("è­¦å‘Š: åˆ†å±‚æ¨¡å¼ä¸‹æ”¶åˆ°éå­—å…¸æ ¼å¼ batchï¼Œè·³è¿‡æƒé‡è®¡ç®—", 'WARNING')
                    return torch.ones(num_major).to(self.device), torch.ones(num_detail).to(self.device)
            
            # è®¡ç®—å¤§ç±»æƒé‡
            major_weights = np.zeros(num_major)
            for c in range(num_major):
                if major_counts[c] > 0:
                    major_weights[c] = total_samples / (num_major * major_counts[c])
                else:
                    major_weights[c] = 1.0
            major_weights = major_weights / major_weights.mean()
            
            # è®¡ç®—å°ç±»æƒé‡
            detail_weights = np.zeros(num_detail)
            for c in range(num_detail):
                if detail_counts[c] > 0:
                    detail_weights[c] = total_samples / (num_detail * detail_counts[c])
                else:
                    detail_weights[c] = 1.0
            detail_weights = detail_weights / detail_weights.mean()
            
            self.logger.log(f"[æƒé‡è®¡ç®—] åˆ†å±‚æ¨¡å¼ - å¤§ç±»æƒé‡å½¢çŠ¶: {major_weights.shape}, å°ç±»æƒé‡å½¢çŠ¶: {detail_weights.shape}")
            
            return (
                torch.from_numpy(major_weights).float().to(self.device),
                torch.from_numpy(detail_weights).float().to(self.device)
            )

        else:
            # ====== æ ‡å‡†æ¨¡å¼æƒé‡è®¡ç®— ======
            label_counts = np.zeros(self.num_classes)
            total_samples = 0
            
            for batch in tqdm(
                self.train_dataloader,
                desc="ç»Ÿè®¡ç±»åˆ«åˆ†å¸ƒ",
                disable=not self.verbose,
                leave=False
            ):
                if isinstance(batch, dict):
                    labels = batch['label']
                else:
                    labels = batch[1]  # å‡è®¾æ˜¯ (data, label) å…ƒç»„
                
                labels = labels.cpu().numpy()
                for label in labels:
                    label_counts[label] += 1
                    total_samples += 1
            
            # è®¡ç®—æƒé‡
            weights = np.zeros(self.num_classes)
            for c in range(self.num_classes):
                if label_counts[c] > 0:
                    # åå‘åŠ æƒ
                    weights[c] = total_samples / (self.num_classes * label_counts[c])
                else:
                    weights[c] = 1.0  # å¦‚æœæŸç±»ä¸å­˜åœ¨ï¼Œæƒé‡ä¸º 1
            
            # å½’ä¸€åŒ–ï¼ˆä½¿å¾—å¹³å‡æƒé‡ä¸º 1ï¼‰
            weights = weights / weights.mean()
            
            # æ‰“å°ç±»åˆ«åˆ†å¸ƒ
            self.logger.log("[æƒé‡è®¡ç®—] ç±»åˆ«åˆ†å¸ƒ:")
            for c in range(self.num_classes):
                count = int(label_counts[c])
                weight = weights[c]
                self.logger.log(f"  ç±»åˆ« {c}: {count:6d} æ ·æœ¬ | æƒé‡: {weight:.4f}")
            
            return torch.from_numpy(weights).float().to(self.device)
    
    def train_epoch(self, epoch: int, num_epochs: int) -> Dict[str, float]:
        """æ‰§è¡Œä¸€ä¸ª epoch çš„è®­ç»ƒ"""
        if self.is_hierarchical:
            return self._train_epoch_hierarchical(epoch, num_epochs)
        else:
            return self._train_epoch_standard(epoch, num_epochs)
    
    def _train_epoch_standard(self, epoch: int, num_epochs: int) -> Dict[str, float]:
        """æ ‡å‡†åˆ†ç±»çš„è®­ç»ƒ"""
        self.model.train()
        
        total_loss = 0.0
        all_predictions = []
        all_targets = []
        
        pbar = tqdm(
            self.train_dataloader,
            desc=f"Epoch {epoch}/{num_epochs}",
            disable=not self.verbose,
            leave=False
        )
        
        for batch_idx, batch in enumerate(pbar):
            # è·å–æ•°æ®
            if isinstance(batch, dict):
                dynamic = batch['dynamic'].to(self.device)
                static = batch['static'].to(self.device)
                labels = batch['label'].to(self.device)
            else:
                # å‡è®¾æ˜¯å…ƒç»„æ ¼å¼
                dynamic, static, labels = batch[0].to(self.device), batch[1].to(self.device), batch[2].to(self.device)
            
            # å‰å‘ä¼ æ’­
            outputs = self.model(dynamic, static)
            if isinstance(outputs, dict):
                logits = outputs['logits']
            else:
                logits = outputs
            
            # è®¡ç®—æŸå¤±
            loss = self.criterion(logits, labels)
            
            # åå‘ä¼ æ’­
            self.optimizer.zero_grad()
            loss.backward()
            self.optimizer.step()
            
            # ç»Ÿè®¡æŒ‡æ ‡
            total_loss += loss.item()
            
            # è·å–é¢„æµ‹ç»“æœ
            predictions = torch.argmax(logits, dim=1).cpu().numpy()
            targets = labels.cpu().numpy()
            
            all_predictions.extend(predictions)
            all_targets.extend(targets)
            
            # æ›´æ–°è¿›åº¦æ¡
            avg_loss = total_loss / (batch_idx + 1)
            pbar.set_postfix({'loss': f'{avg_loss:.4f}'})
        
        # è®¡ç®—æŒ‡æ ‡
        metrics = MetricsCalculator.compute_metrics(
            np.array(all_predictions),
            np.array(all_targets),
            self.num_classes,
            average_methods=['macro', 'weighted']
        )
        
        metrics['train_loss'] = total_loss / len(self.train_dataloader)
        metrics['train_accuracy'] = metrics.pop('accuracy')
        metrics['train_f1_macro'] = metrics.pop('f1_macro', 0.0)
        metrics['train_f1_weighted'] = metrics.pop('f1_weighted', 0.0)
        
        return metrics
    
    def _train_epoch_hierarchical(self, epoch: int, num_epochs: int) -> Dict[str, float]:
        """åˆ†å±‚åˆ†ç±»çš„è®­ç»ƒ"""
        self.model.train()
        
        total_loss = 0.0
        total_major_loss = 0.0
        total_detail_loss = 0.0
        all_major_preds = []
        all_major_targets = []
        all_detail_preds = []
        all_detail_targets = []
        
        pbar = tqdm(
            self.train_dataloader,
            desc=f"Epoch {epoch}/{num_epochs}",
            disable=not self.verbose,
            leave=False
        )
        
        # æŸå¤±æƒé‡ï¼ˆå¯ä»é…ç½®ä¸­è¯»å–ï¼‰
        weight_major = 0.3
        weight_detail = 0.7
        
        for batch_idx, batch in enumerate(pbar):
            # è·å–æ•°æ®
            if isinstance(batch, dict):
                dynamic = batch['dynamic'].to(self.device)
                static = batch['static'].to(self.device)
                major_labels = batch['major_label'].to(self.device)
                detail_labels = batch['detail_label'].to(self.device)
            else:
                raise ValueError("åˆ†å±‚åˆ†ç±»å¿…é¡»ä½¿ç”¨å­—å…¸æ ¼å¼çš„ batch")
            
            # å‰å‘ä¼ æ’­ï¼šå¿…é¡»ä¼ å…¥ major_labels ä»¥å¯ç”¨ Teacher Forcing
            outputs = self.model(dynamic, static, major_labels=major_labels)
            
            major_logits = outputs['major_logits']  # (B, num_major)
            detail_logits = outputs['detail_logits']  # (B, max_detail)
            
            # è®¡ç®—ä¸¤çº§æŸå¤±
            loss_major = self.criterion_major(major_logits, major_labels)
            loss_detail = self.criterion_detail(detail_logits, detail_labels)
            
            # åŠ æƒç»„åˆ
            loss = weight_major * loss_major + weight_detail * loss_detail
            
            # åå‘ä¼ æ’­
            self.optimizer.zero_grad()
            loss.backward()
            self.optimizer.step()
            
            # ç»Ÿè®¡æŒ‡æ ‡
            total_loss += loss.item()
            total_major_loss += loss_major.item()
            total_detail_loss += loss_detail.item()
            
            # è·å–é¢„æµ‹ç»“æœ
            major_preds = torch.argmax(major_logits, dim=1).cpu().numpy()
            major_targets = major_labels.cpu().numpy()
            detail_preds = torch.argmax(detail_logits, dim=1).cpu().numpy()
            detail_targets = detail_labels.cpu().numpy()
            
            all_major_preds.extend(major_preds)
            all_major_targets.extend(major_targets)
            all_detail_preds.extend(detail_preds)
            all_detail_targets.extend(detail_targets)
            
            # æ›´æ–°è¿›åº¦æ¡
            avg_loss = total_loss / (batch_idx + 1)
            pbar.set_postfix({'loss': f'{avg_loss:.4f}'})
        
        # è®¡ç®—æŒ‡æ ‡
        major_metrics = MetricsCalculator.compute_metrics(
            np.array(all_major_preds),
            np.array(all_major_targets),
            len(self.hierarchical_map),
            average_methods=['macro']
        )
        
        detail_metrics = MetricsCalculator.compute_metrics(
            np.array(all_detail_preds),
            np.array(all_detail_targets),
            self.num_classes,
            average_methods=['macro']
        )
        
        # å±‚çº§å‡†ç¡®ç‡ï¼ˆå¤§ç±»å’Œå°ç±»éƒ½é¢„æµ‹æ­£ç¡®ï¼‰
        hierarchical_correct = (
            np.array(all_major_preds) == np.array(all_major_targets)
        ) & (
            np.array(all_detail_preds) == np.array(all_detail_targets)
        )
        hierarchical_accuracy = hierarchical_correct.mean()
        
        metrics = {
            'train_loss': total_loss / len(self.train_dataloader),
            'train_major_loss': total_major_loss / len(self.train_dataloader),
            'train_detail_loss': total_detail_loss / len(self.train_dataloader),
            'train_major_accuracy': major_metrics.get('accuracy', 0.0),
            'train_detail_accuracy': detail_metrics.get('accuracy', 0.0),
            'train_hierarchical_accuracy': hierarchical_accuracy,
        }
        
        return metrics
    
    def validate(self, epoch: Optional[int] = None) -> Dict[str, float]:
        """
        åœ¨éªŒè¯é›†ä¸Šè¯„ä¼°æ¨¡å‹
        """
        if self.val_dataloader is None:
            return {}
        
        if self.is_hierarchical:
            return self._validate_hierarchical(epoch=epoch)
        else:
            return self._validate_standard()
    
    def _validate_standard(self) -> Dict[str, float]:
        """æ ‡å‡†åˆ†ç±»çš„éªŒè¯"""
        self.model.eval()
        
        total_loss = 0.0
        all_predictions = []
        all_targets = []
        
        pbar = tqdm(
            self.val_dataloader,
            desc="éªŒè¯",
            disable=not self.verbose,
            leave=False
        )
        
        with torch.no_grad():
            for batch in pbar:
                # è·å–æ•°æ®
                if isinstance(batch, dict):
                    dynamic = batch['dynamic'].to(self.device)
                    static = batch['static'].to(self.device)
                    labels = batch['label'].to(self.device)
                else:
                    dynamic, static, labels = batch[0].to(self.device), batch[1].to(self.device), batch[2].to(self.device)
                
                # å‰å‘ä¼ æ’­
                outputs = self.model(dynamic, static)
                if isinstance(outputs, dict):
                    logits = outputs['logits']
                else:
                    logits = outputs
                
                # è®¡ç®—æŸå¤±
                loss = self.criterion(logits, labels)
                total_loss += loss.item()
                
                # è·å–é¢„æµ‹ç»“æœ
                predictions = torch.argmax(logits, dim=1).cpu().numpy()
                targets = labels.cpu().numpy()
                
                all_predictions.extend(predictions)
                all_targets.extend(targets)
        
        # è®¡ç®—æŒ‡æ ‡
        metrics = MetricsCalculator.compute_metrics(
            np.array(all_predictions),
            np.array(all_targets),
            self.num_classes,
            average_methods=['macro', 'weighted']
        )
        
        metrics['val_loss'] = total_loss / len(self.val_dataloader)
        metrics['val_accuracy'] = metrics.pop('accuracy')
        metrics['val_f1_macro'] = metrics.pop('f1_macro', 0.0)
        metrics['val_f1_weighted'] = metrics.pop('f1_weighted', 0.0)
        metrics['val_iou'] = metrics.pop('iou', 0.0)
        
        return metrics
    
    def _validate_hierarchical(self, epoch: Optional[int] = None) -> Dict[str, float]:
        """
        åˆ†å±‚åˆ†ç±»çš„éªŒè¯
        ã€åŠŸèƒ½ã€‘æ”¯æŒè¾“å‡ºé¢„æµ‹ç»“æœåˆ° CSV
        """
        self.model.eval()
        
        total_loss = 0.0
        total_major_loss = 0.0
        total_detail_loss = 0.0
        
        # ç”¨äºæ”¶é›†æ‰€æœ‰ç»“æœä»¥ä¾¿ä¿å­˜ CSV
        all_results = {
            'major_true': [], 'major_pred': [],
            'detail_true': [], 'detail_pred': []
        }
        
        pbar = tqdm(
            self.val_dataloader,
            desc="éªŒè¯",
            disable=not self.verbose,
            leave=False
        )
        
        weight_major = 0.3
        weight_detail = 0.7
        
        with torch.no_grad():
            for batch in pbar:
                # è·å–æ•°æ®
                if isinstance(batch, dict):
                    dynamic = batch['dynamic'].to(self.device)
                    static = batch['static'].to(self.device)
                    major_labels = batch['major_label'].to(self.device)
                    detail_labels = batch['detail_label'].to(self.device)
                else:
                    raise ValueError("åˆ†å±‚åˆ†ç±»å¿…é¡»ä½¿ç”¨å­—å…¸æ ¼å¼çš„ batch")
                
                # å‰å‘ä¼ æ’­ (éªŒè¯ä¸ä½¿ç”¨ major_labels)
                outputs = self.model(dynamic, static)
                major_logits = outputs['major_logits']
                detail_logits = outputs['detail_logits']
                
                # è®¡ç®—ä¸¤çº§æŸå¤±
                loss_major = self.criterion_major(major_logits, major_labels)
                loss_detail = self.criterion_detail(detail_logits, detail_labels)
                loss = weight_major * loss_major + weight_detail * loss_detail
                
                total_loss += loss.item()
                total_major_loss += loss_major.item()
                total_detail_loss += loss_detail.item()
                
                # è·å–é¢„æµ‹ç»“æœ
                major_preds = torch.argmax(major_logits, dim=1).cpu().numpy()
                major_targets = major_labels.cpu().numpy()
                detail_preds = torch.argmax(detail_logits, dim=1).cpu().numpy()
                detail_targets = detail_labels.cpu().numpy()
                
                # æ”¶é›†ç»“æœ
                all_results['major_true'].extend(major_targets)
                all_results['major_pred'].extend(major_preds)
                all_results['detail_true'].extend(detail_targets)
                all_results['detail_pred'].extend(detail_preds)
        
        # ä¿å­˜ Debug è¡¨æ ¼
        if epoch is not None:
            try:
                # æ„é€  DataFrame
                df = pd.DataFrame(all_results)
                
                # æ˜ å°„ ID ä¸ºä¸­æ–‡åç§° (å¦‚æœæ˜ å°„è¡¨å­˜åœ¨)
                if hasattr(self, 'major_id_to_name') and self.major_id_to_name:
                    df['major_true_name'] = df['major_true'].map(self.major_id_to_name)
                    df['major_pred_name'] = df['major_pred'].map(self.major_id_to_name)
                    df['detail_true_name'] = df['detail_true'].map(self.detail_id_to_name)
                    df['detail_pred_name'] = df['detail_pred'].map(self.detail_id_to_name)
                    
                    # è°ƒæ•´åˆ—é¡ºåº
                    cols = ['major_true_name', 'major_pred_name', 'detail_true_name', 'detail_pred_name',
                            'major_true', 'major_pred', 'detail_true', 'detail_pred']
                    df = df[cols]
                
                # å¢åŠ ä¸€åˆ—åˆ¤æ–­æ˜¯å¦æ­£ç¡®
                df['major_correct'] = df['major_true'] == df['major_pred']
                df['detail_correct'] = df['detail_true'] == df['detail_pred']
                
                # ä¿å­˜æ–‡ä»¶
                filename = f'val_predictions_epoch_{epoch}.csv'
                save_path = self.output_dir / filename
                df.to_csv(save_path, index=False, encoding='utf-8-sig')
                if self.verbose:
                    self.logger.log(f"ğŸ“ éªŒè¯é›†é¢„æµ‹ç»“æœå·²ä¿å­˜: {filename}")
                
            except Exception as e:
                self.logger.log(f"âš ï¸ ä¿å­˜éªŒè¯è¡¨æ ¼å¤±è´¥: {e}", level='WARNING')
        
        # è®¡ç®—æŒ‡æ ‡
        major_metrics = MetricsCalculator.compute_metrics(
            np.array(all_results['major_pred']),
            np.array(all_results['major_true']),
            len(self.hierarchical_map),
            average_methods=['macro']
        )
        
        detail_metrics = MetricsCalculator.compute_metrics(
            np.array(all_results['detail_pred']),
            np.array(all_results['detail_true']),
            self.num_classes,
            average_methods=['macro']
        )
        
        # å±‚çº§å‡†ç¡®ç‡
        hierarchical_correct = (
            np.array(all_results['major_pred']) == np.array(all_results['major_true'])
        ) & (
            np.array(all_results['detail_pred']) == np.array(all_results['detail_true'])
        )
        hierarchical_accuracy = hierarchical_correct.mean()
        
        metrics = {
            'val_loss': total_loss / len(self.val_dataloader),
            'val_major_loss': total_major_loss / len(self.val_dataloader),
            'val_detail_loss': total_detail_loss / len(self.val_dataloader),
            'val_major_accuracy': major_metrics.get('accuracy', 0.0),
            'val_detail_accuracy': detail_metrics.get('accuracy', 0.0),
            'val_hierarchical_accuracy': hierarchical_accuracy,
        }
        
        return metrics
    
    def save_checkpoint(self, epoch: int, is_best: bool = False):
        """ä¿å­˜æ¨¡å‹ checkpoint"""
        checkpoint = {
            'epoch': epoch,
            'model_state_dict': self.model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict() if self.optimizer else None,
            'best_val_f1': self.best_val_f1,
        }
        
        # ä¿å­˜æœ€åçš„æ¨¡å‹
        last_path = self.output_dir / 'last_model.pth'
        torch.save(checkpoint, last_path)
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if is_best:
            best_path = self.output_dir / 'best_model.pth'
            torch.save(checkpoint, best_path)
            self.logger.log(f"ğŸ’¾ ä¿å­˜æœ€ä½³æ¨¡å‹: Epoch {epoch}")
    
    def load_checkpoint(self, checkpoint_path: Path) -> int:
        """åŠ è½½æ¨¡å‹ checkpoint"""
        checkpoint = torch.load(checkpoint_path, map_location=self.device)
        self.model.load_state_dict(checkpoint['model_state_dict'])
        
        if self.optimizer and checkpoint.get('optimizer_state_dict'):
            self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
        
        self.best_val_f1 = checkpoint.get('best_val_f1', -np.inf)
        epoch = checkpoint.get('epoch', 0)
        
        self.logger.log(f"âœ… åŠ è½½ checkpoint: {checkpoint_path}")
        
        return epoch
    
    def train(
        self,
        num_epochs: int = 50,
        learning_rate: float = 1e-3,
        weight_decay: float = 1e-4,
        patience: int = 10,
        debug: bool = False,
        resume_from: Optional[Path] = None,
    ) -> Dict:
        """å®Œæ•´çš„è®­ç»ƒå¾ªç¯"""
        # Debug æ¨¡å¼
        if debug:
            self.logger.print_header("å¼€å§‹ Overfit æµ‹è¯• (Debug Mode)...")
            num_epochs = 10
            patience = 1000  # ç¦ç”¨æ—©åœ
        else:
            self.logger.print_header("å¼€å§‹è®­ç»ƒ")
        
        # åˆå§‹åŒ–ä¼˜åŒ–å™¨
        self.optimizer = optim.Adam(
            self.model.parameters(),
            lr=learning_rate,
            weight_decay=weight_decay,
        )
        
        # åˆå§‹åŒ–æŸå¤±å‡½æ•°
        if self.is_hierarchical:
            self.criterion_major = WeightedCrossEntropyLoss(weight=self.major_class_weights)
            self.criterion_detail = WeightedCrossEntropyLoss(weight=self.detail_class_weights)
            self.logger.log("å·²åˆå§‹åŒ–åˆ†å±‚æŸå¤±å‡½æ•° (Major & Detail)")
        else:
            self.criterion = WeightedCrossEntropyLoss(weight=self.class_weights)
            self.logger.log("å·²åˆå§‹åŒ–æ ‡å‡†æŸå¤±å‡½æ•°")
        
        self.logger.log(f"å­¦ä¹ ç‡: {learning_rate}")
        self.logger.log(f"æƒé‡è¡°å‡: {weight_decay}")
        self.logger.log(f"æ—©åœè€å¿ƒ: {patience} epochs")
        
        # æ¢å¤è®­ç»ƒï¼ˆå¦‚æœæŒ‡å®šï¼‰
        start_epoch = 1
        if resume_from and resume_from.exists():
            start_epoch = self.load_checkpoint(resume_from) + 1
        
        # è®­ç»ƒå¾ªç¯
        start_time = time.time()
        
        for epoch in range(start_epoch, num_epochs + 1):
            # è®­ç»ƒä¸€ä¸ª epoch
            train_metrics = self.train_epoch(epoch, num_epochs)
            
            # éªŒè¯
            val_metrics = self.validate(epoch=epoch) if self.val_dataloader else {}
            
            # åˆå¹¶æŒ‡æ ‡
            epoch_metrics = {**train_metrics, **val_metrics}
            
            # è®°å½•æŒ‡æ ‡
            for key, value in epoch_metrics.items():
                if key in self.history:
                    self.history[key].append(value)
            
            self.logger.log_metrics(epoch, epoch_metrics)
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯æœ€ä½³æ¨¡å‹
            if self.is_hierarchical:
                val_metric = val_metrics.get('val_hierarchical_accuracy', -np.inf)
            else:
                val_metric = val_metrics.get('val_f1_macro', -np.inf)
            
            is_best = val_metric > self.best_val_f1
            
            if is_best:
                self.best_val_f1 = val_metric
                self.best_epoch = epoch
                self.patience_counter = 0
            else:
                self.patience_counter += 1
            
            # æ‰“å° epoch æ‘˜è¦
            self.logger.print_epoch_summary(epoch, num_epochs, epoch_metrics, is_best=is_best)
            
            # ä¿å­˜ checkpoint
            self.save_checkpoint(epoch, is_best=is_best)
            
            # æ—©åœ
            if self.patience_counter >= patience:
                self.logger.log(f"â¹ï¸  æ—©åœï¼š{patience} ä¸ª epoch æ— æ”¹è¿›")
                break
        
        # è®­ç»ƒå®Œæˆ
        elapsed_time = time.time() - start_time
        
        self.logger.print_header("è®­ç»ƒå®Œæˆ")
        self.logger.log(f"æ€»è€—æ—¶: {elapsed_time / 3600:.2f} å°æ—¶")
        
        if self.is_hierarchical:
            self.logger.log(f"æœ€ä½³æ¨¡å‹: Epoch {self.best_epoch} (Val å±‚çº§å‡†ç¡®ç‡: {self.best_val_f1:.4f})")
        else:
            self.logger.log(f"æœ€ä½³æ¨¡å‹: Epoch {self.best_epoch} (Val F1: {self.best_val_f1:.4f})")
        
        # åŠ è½½æœ€ä½³æ¨¡å‹
        best_model_path = self.output_dir / 'best_model.pth'
        if best_model_path.exists():
            self.load_checkpoint(best_model_path)
            self.logger.log("âœ… åŠ è½½æœ€ä½³æ¨¡å‹æƒé‡")
        
        # ä¿å­˜è®­ç»ƒå†å²
        self.logger.save_metrics()
        self.logger.log(f"ğŸ’¾ è®­ç»ƒå†å²å·²ä¿å­˜: {self.logger.metrics_file}")
        
        return self.history
    
    def test(self, test_loader=None) -> Dict[str, float]:
        """åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°æ¨¡å‹"""
        if test_loader is None:
            test_loader = self.test_dataloader
        
        if test_loader is None:
            self.logger.log("âŒ æœªæä¾›æµ‹è¯•æ•°æ®åŠ è½½å™¨")
            return {}
        
        if self.is_hierarchical:
            return self._test_hierarchical(test_loader)
        else:
            return self._test_standard(test_loader)
    
    def _test_standard(self, test_loader) -> Dict[str, float]:
        """æ ‡å‡†åˆ†ç±»çš„æµ‹è¯•"""
        self.logger.print_header("æµ‹è¯•é˜¶æ®µ")
        
        self.model.eval()
        
        all_predictions = []
        all_targets = []
        all_probabilities = []
        
        pbar = tqdm(
            test_loader,
            desc="æµ‹è¯•",
            disable=not self.verbose,
        )
        
        with torch.no_grad():
            for batch in pbar:
                # è·å–æ•°æ®
                if isinstance(batch, dict):
                    dynamic = batch['dynamic'].to(self.device)
                    static = batch['static'].to(self.device)
                    labels = batch['label'].to(self.device)
                else:
                    dynamic, static, labels = batch[0].to(self.device), batch[1].to(self.device), batch[2].to(self.device)
                
                # å‰å‘ä¼ æ’­
                outputs = self.model(dynamic, static)
                if isinstance(outputs, dict):
                    logits = outputs['logits']
                else:
                    logits = outputs
                
                # è·å–é¢„æµ‹ç»“æœ
                probabilities = F.softmax(logits, dim=1)
                predictions = torch.argmax(logits, dim=1).cpu().numpy()
                targets = labels.cpu().numpy()
                
                all_predictions.extend(predictions)
                all_targets.extend(targets)
                all_probabilities.extend(probabilities.cpu().numpy())
        
        # ã€æ–°å¢ã€‘ä¿å­˜æµ‹è¯•é›†ç»“æœåˆ° CSV
        try:
            df = pd.DataFrame({
                'target': all_targets,
                'prediction': all_predictions
            })
            # å¦‚æœæœ‰æ¦‚ç‡å€¼ä¹Ÿå¯ä»¥ä¿å­˜ï¼ˆå¯é€‰ï¼‰
            # df['probability'] = np.max(all_probabilities, axis=1)
            
            save_path = self.output_dir / 'test_predictions.csv'
            df.to_csv(save_path, index=False, encoding='utf-8-sig')
            self.logger.log(f"ğŸ“ æµ‹è¯•é›†é¢„æµ‹ç»“æœå·²ä¿å­˜: {save_path}")
        except Exception as e:
            self.logger.log(f"âš ï¸ ä¿å­˜æµ‹è¯•ç»“æœCSVå¤±è´¥: {e}", level='WARNING')
        
        # è®¡ç®—æŒ‡æ ‡
        metrics = MetricsCalculator.compute_metrics(
            np.array(all_predictions),
            np.array(all_targets),
            self.num_classes,
        )
        
        # æ‰“å°ç»“æœ
        self.logger.log("\nğŸ“Š æµ‹è¯•ç»“æœ:")
        self.logger.log(f"  Accuracy: {metrics['accuracy']:.4f}")
        self.logger.log(f"  Precision: {metrics['precision']:.4f}")
        self.logger.log(f"  Recall: {metrics['recall']:.4f}")
        self.logger.log(f"  F1 (Macro): {metrics.get('f1_macro', 0):.4f}")
        self.logger.log(f"  F1 (Weighted): {metrics.get('f1_weighted', 0):.4f}")
        self.logger.log(f"  IoU: {metrics['iou']:.4f}")
        
        # æ··æ·†çŸ©é˜µ
        cm = MetricsCalculator.compute_confusion_matrix(
            np.array(all_predictions),
            np.array(all_targets)
        )
        
        # ä¿å­˜æ··æ·†çŸ©é˜µ
        cm_file = self.output_dir / 'confusion_matrix.npy'
        np.save(cm_file, cm)
        self.logger.log(f"ğŸ’¾ æ··æ·†çŸ©é˜µå·²ä¿å­˜: {cm_file}")
        
        return metrics
    
    def _test_hierarchical(self, test_loader) -> Dict[str, float]:
        """åˆ†å±‚åˆ†ç±»çš„æµ‹è¯•"""
        self.logger.print_header("æµ‹è¯•é˜¶æ®µ (åˆ†å±‚åˆ†ç±»)")
        
        self.model.eval()
        
        # ç”¨äºæ”¶é›†ç»“æœ
        all_results = {
            'major_true': [], 'major_pred': [],
            'detail_true': [], 'detail_pred': []
        }
        
        pbar = tqdm(
            test_loader,
            desc="æµ‹è¯•",
            disable=not self.verbose,
        )
        
        with torch.no_grad():
            for batch in pbar:
                # è·å–æ•°æ®
                if isinstance(batch, dict):
                    dynamic = batch['dynamic'].to(self.device)
                    static = batch['static'].to(self.device)
                    major_labels = batch['major_label'].to(self.device)
                    detail_labels = batch['detail_label'].to(self.device)
                else:
                    raise ValueError("åˆ†å±‚åˆ†ç±»å¿…é¡»ä½¿ç”¨å­—å…¸æ ¼å¼çš„ batch")
                
                # å‰å‘ä¼ æ’­
                outputs = self.model(dynamic, static)
                major_logits = outputs['major_logits']
                detail_logits = outputs['detail_logits']
                
                # è·å–é¢„æµ‹ç»“æœ
                major_preds = torch.argmax(major_logits, dim=1).cpu().numpy()
                major_targets = major_labels.cpu().numpy()
                detail_preds = torch.argmax(detail_logits, dim=1).cpu().numpy()
                detail_targets = detail_labels.cpu().numpy()
                
                # æ”¶é›†ç»“æœ
                all_results['major_true'].extend(major_targets)
                all_results['major_pred'].extend(major_preds)
                all_results['detail_true'].extend(detail_targets)
                all_results['detail_pred'].extend(detail_preds)
        
        # ã€æ–°å¢ã€‘ä¿å­˜æµ‹è¯•ç»“æœè¡¨æ ¼
        try:
            df = pd.DataFrame(all_results)
            
            # æ˜ å°„ ID ä¸ºä¸­æ–‡åç§° (å¦‚æœæ˜ å°„è¡¨å­˜åœ¨)
            if hasattr(self, 'major_id_to_name') and self.major_id_to_name:
                df['major_true_name'] = df['major_true'].map(self.major_id_to_name)
                df['major_pred_name'] = df['major_pred'].map(self.major_id_to_name)
                df['detail_true_name'] = df['detail_true'].map(self.detail_id_to_name)
                df['detail_pred_name'] = df['detail_pred'].map(self.detail_id_to_name)
                
                # è°ƒæ•´åˆ—é¡ºåº
                cols = ['major_true_name', 'major_pred_name', 'detail_true_name', 'detail_pred_name',
                        'major_true', 'major_pred', 'detail_true', 'detail_pred']
                df = df[cols]
            
            # å¢åŠ ä¸€åˆ—åˆ¤æ–­æ˜¯å¦æ­£ç¡®
            df['major_correct'] = df['major_true'] == df['major_pred']
            df['detail_correct'] = df['detail_true'] == df['detail_pred']
            
            # ä¿å­˜æ–‡ä»¶
            save_path = self.output_dir / 'test_predictions.csv'
            df.to_csv(save_path, index=False, encoding='utf-8-sig')
            self.logger.log(f"ğŸ“ æµ‹è¯•é›†é¢„æµ‹ç»“æœå·²ä¿å­˜: {save_path}")
            
        except Exception as e:
            self.logger.log(f"âš ï¸ ä¿å­˜æµ‹è¯•è¡¨æ ¼å¤±è´¥: {e}", level='WARNING')

        # è®¡ç®—æŒ‡æ ‡
        major_metrics = MetricsCalculator.compute_metrics(
            np.array(all_results['major_pred']),
            np.array(all_results['major_true']),
            len(self.hierarchical_map),
        )
        
        detail_metrics = MetricsCalculator.compute_metrics(
            np.array(all_results['detail_pred']),
            np.array(all_results['detail_true']),
            self.num_classes,
        )
        
        # å±‚çº§å‡†ç¡®ç‡
        hierarchical_correct = (
            np.array(all_results['major_pred']) == np.array(all_results['major_true'])
        ) & (
            np.array(all_results['detail_pred']) == np.array(all_results['detail_true'])
        )
        hierarchical_accuracy = hierarchical_correct.mean()
        
        # æ‰“å°ç»“æœ
        self.logger.log("\nğŸ“Š æµ‹è¯•ç»“æœ (åˆ†å±‚åˆ†ç±»):")
        self.logger.log(f"  å¤§ç±»å‡†ç¡®ç‡: {major_metrics['accuracy']:.4f}")
        self.logger.log(f"  å°ç±»å‡†ç¡®ç‡: {detail_metrics['accuracy']:.4f}")
        self.logger.log(f"  å±‚çº§å‡†ç¡®ç‡: {hierarchical_accuracy:.4f}")
        
        metrics = {
            'major_accuracy': major_metrics['accuracy'],
            'detail_accuracy': detail_metrics['accuracy'],
            'hierarchical_accuracy': hierarchical_accuracy,
            'major_f1': major_metrics.get('f1_macro', 0.0),
            'detail_f1': detail_metrics.get('f1_macro', 0.0),
        }
        
        return metrics