"""
LabelEncoder: æ ‡ç­¾ç¼–ç ä¸ç±»åˆ«æ˜ å°„æ¨¡å—

åŠŸèƒ½ï¼š
1. è¯»å– CSV æ ‡ç­¾æ–‡ä»¶
2. ç”Ÿæˆç±»åˆ«æ˜ å°„ï¼ˆè¯¦ç»†ç±»åˆ«å’Œå¤§ç±»ï¼‰
3. ç©ºé—´æŠ•å½±è½¬æ¢ï¼ˆç»çº¬åº¦ â†’ Target CRSï¼‰
4. å±‚çº§æ ‡ç­¾å¤„ç†ï¼ˆå¤§ç±» + è¯¦ç»†ç±»åˆ«ï¼‰
5. ä¿å­˜æ˜ å°„åˆ° JSON æ–‡ä»¶
"""

import json
import logging
import sys
from pathlib import Path
from typing import Dict, List, Tuple, Optional
from collections import OrderedDict

import pandas as pd
import geopandas as gpd
from shapely.geometry import Point


class LabelEncoder:
    """
    æ ‡ç­¾ç¼–ç ç±»
    
    åŠŸèƒ½ï¼š
    1. åŠ è½½ CSV æ ‡ç­¾æ–‡ä»¶å¹¶éªŒè¯
    2. ç”Ÿæˆç±»åˆ«æ˜ å°„ï¼ˆå¤§ç±»å’Œè¯¦ç»†ç±»åˆ«ï¼‰
    3. è¿›è¡Œç©ºé—´æŠ•å½±è½¬æ¢
    4. ç”Ÿæˆå±‚çº§æ ‡ç­¾
    5. ä¿å­˜æ˜ å°„åˆ°å®éªŒç›®å½•
    
    ä½¿ç”¨ç¤ºä¾‹ï¼š
        encoder = LabelEncoder(
            config=config,
            csv_path=csv_path,
            output_dir=output_dir
        )
        detailed_map = encoder.get_detailed_labels_map()
        major_map = encoder.get_major_labels_map()
        gdf = encoder.get_geodataframe()
    """
    
    def __init__(
        self,
        config: 'ConfigManager',
        csv_path: Optional[Path] = None,
        output_dir: Optional[Path] = None,
        target_crs: Optional[str] = None,
    ):
        """
        åˆå§‹åŒ– LabelEncoder
        
        Args:
            config: ConfigManager å¯¹è±¡
            csv_path: CSV æ ‡ç­¾æ–‡ä»¶è·¯å¾„ï¼ˆå¦‚æœä¸º Noneï¼Œåˆ™ä» config è¯»å–ï¼‰
            output_dir: è¾“å‡ºç›®å½•ï¼ˆå¦‚æœä¸º Noneï¼Œåˆ™ä» config è¯»å–ï¼‰
            target_crs: ç›®æ ‡æŠ•å½±ç³»ç»Ÿï¼ˆå¦‚æœä¸º Noneï¼Œåˆ™ä» config è¯»å–ï¼‰
        
        Raises:
            FileNotFoundError: CSV æ–‡ä»¶ä¸å­˜åœ¨
            ValueError: é…ç½®æˆ–æ•°æ®æ ¼å¼é”™è¯¯
        """
        self._setup_logging()
        logger = logging.getLogger(__name__)
        
        # ä¿å­˜é…ç½®
        self.config = config
        
        # è§£æå‚æ•°
        self.csv_path = Path(csv_path) if csv_path else config.get_resolved_path('csv_labels')
        self.output_dir = Path(output_dir) if output_dir else config.get_experiment_output_dir()
        self.target_crs = target_crs or config.get('data_specs.spatial.target_crs')
        
        logger.info(f"ğŸ“‚ CSV è·¯å¾„: {self.csv_path}")
        logger.info(f"ğŸ“‚ è¾“å‡ºç›®å½•: {self.output_dir}")
        logger.info(f"ğŸ—ºï¸  ç›®æ ‡æŠ•å½±: {self.target_crs}")
        
        # éªŒè¯æ–‡ä»¶å­˜åœ¨
        if not self.csv_path.exists():
            error_msg = f"âŒ CSV æ–‡ä»¶ä¸å­˜åœ¨: {self.csv_path}"
            logger.error(error_msg)
            raise FileNotFoundError(error_msg)
        
        # è¯»å–é…ç½®ä¸­çš„åˆ—åæ˜ å°„
        csv_cols_config = config.get('data_specs.csv_columns')
        self.id_col = csv_cols_config.get('id')
        self.lon_col = csv_cols_config.get('longitude')
        self.lat_col = csv_cols_config.get('latitude')
        self.major_class_col = csv_cols_config.get('major_class')
        self.detail_class_col = csv_cols_config.get('detail_class')
        
        logger.info(f"ğŸ“‹ CSV åˆ—é…ç½®:")
        logger.info(f"   ID åˆ—: {self.id_col}")
        logger.info(f"   ç»åº¦åˆ—: {self.lon_col}")
        logger.info(f"   çº¬åº¦åˆ—: {self.lat_col}")
        logger.info(f"   å¤§ç±»åˆ—: {self.major_class_col}")
        logger.info(f"   è¯¦ç»†ç±»åˆ«åˆ—: {self.detail_class_col}")
        
        # åˆå§‹åŒ–æ•°æ®å­˜å‚¨
        self.df = None
        self.gdf = None
        self.detailed_labels_map = None
        self.major_labels_map = None
        self.inverse_detailed_map = None
        self.inverse_major_map = None
        
        # åŠ è½½å’Œå¤„ç†æ•°æ®
        logger.info("ğŸ” å¼€å§‹å¤„ç†æ ‡ç­¾...")
        self._load_csv()
        self._validate_columns()
        self._generate_labels_maps()
        self._transform_crs()
        logger.info("âœ… æ ‡ç­¾å¤„ç†å®Œæˆ")
        
        # ä¿å­˜æ˜ å°„
        self._save_maps()
    
    @staticmethod
    def _setup_logging():
        """é…ç½®æ—¥å¿—ç³»ç»Ÿ"""
        if not logging.getLogger(__name__).handlers:
            handler = logging.StreamHandler(sys.stdout)
            formatter = logging.Formatter(
                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
            )
            handler.setFormatter(formatter)
            logging.getLogger(__name__).addHandler(handler)
            logging.getLogger(__name__).setLevel(logging.INFO)
    
    def _load_csv(self):
        """
        åŠ è½½ CSV æ–‡ä»¶
        
        Raises:
            ValueError: CSV æ ¼å¼é”™è¯¯
        """
        logger = logging.getLogger(__name__)
        
        try:
            self.df = pd.read_csv(self.csv_path, encoding='utf-8')
            logger.info(f"âœ… CSV åŠ è½½æˆåŠŸ: {len(self.df)} è¡Œ")
        except UnicodeDecodeError:
            # å°è¯•å…¶ä»–ç¼–ç 
            self.df = pd.read_csv(self.csv_path, encoding='gbk')
            logger.info(f"âœ… CSV åŠ è½½æˆåŠŸï¼ˆä½¿ç”¨ GBK ç¼–ç ï¼‰: {len(self.df)} è¡Œ")
        except Exception as e:
            error_msg = f"âŒ CSV åŠ è½½å¤±è´¥: {e}"
            logger.error(error_msg)
            raise ValueError(error_msg)
    
    def _validate_columns(self):
        """
        éªŒè¯å¿…è¦çš„åˆ—æ˜¯å¦å­˜åœ¨
        
        Raises:
            ValueError: ç¼ºå°‘å¿…è¦åˆ—
        """
        logger = logging.getLogger(__name__)
        
        required_columns = [
            self.id_col,
            self.lon_col,
            self.lat_col,
            self.major_class_col,
            self.detail_class_col,
        ]
        
        missing_columns = [col for col in required_columns if col not in self.df.columns]
        
        if missing_columns:
            error_msg = f"âŒ CSV ä¸­ç¼ºå°‘åˆ—: {missing_columns}"
            logger.error(error_msg)
            logger.error(f"   ç°æœ‰åˆ—: {list(self.df.columns)}")
            raise ValueError(error_msg)
        
        # æ£€æŸ¥æ•°æ®å®Œæ•´æ€§
        null_counts = {
            col: self.df[col].isnull().sum()
            for col in required_columns
        }
        
        for col, null_count in null_counts.items():
            if null_count > 0:
                logger.warning(f"âš ï¸  åˆ— '{col}' åŒ…å« {null_count} ä¸ªç©ºå€¼")
        
        logger.info(f"âœ… æ‰€æœ‰å¿…è¦åˆ—éƒ½å­˜åœ¨")
    
    def _generate_labels_maps(self):
        """
        ç”Ÿæˆç±»åˆ«æ˜ å°„
        
        åˆ›å»ºä¸¤ä¸ªæ˜ å°„ï¼š
        1. detailed_labels_map: è¯¦ç»†ç±»åˆ« â†’ æ•°å­—æ ‡ç­¾
        2. major_labels_map: å¤§ç±» â†’ æ•°å­—æ ‡ç­¾
        """
        logger = logging.getLogger(__name__)
        
        # ç”Ÿæˆè¯¦ç»†ç±»åˆ«æ˜ å°„
        detailed_categories = sorted(self.df[self.detail_class_col].unique())
        self.detailed_labels_map = {
            cat: idx for idx, cat in enumerate(detailed_categories)
        }
        self.inverse_detailed_map = {v: k for k, v in self.detailed_labels_map.items()}
        
        logger.info(f"ğŸ“Š è¯¦ç»†ç±»åˆ«æ˜ å°„ ({len(self.detailed_labels_map)} ç±»):")
        for cat, idx in sorted(self.detailed_labels_map.items(), key=lambda x: x[1]):
            logger.info(f"   {idx}: {cat}")
        
        # ç”Ÿæˆå¤§ç±»æ˜ å°„
        major_categories = sorted(self.df[self.major_class_col].unique())
        self.major_labels_map = {
            cat: idx for idx, cat in enumerate(major_categories)
        }
        self.inverse_major_map = {v: k for k, v in self.major_labels_map.items()}
        
        logger.info(f"ğŸ“Š å¤§ç±»æ˜ å°„ ({len(self.major_labels_map)} ç±»):")
        for cat, idx in sorted(self.major_labels_map.items(), key=lambda x: x[1]):
            logger.info(f"   {idx}: {cat}")
        
        # ç”Ÿæˆå±‚çº§æ˜ å°„ï¼ˆå¤§ç±» â†’ è¯¦ç»†ç±»åˆ«åˆ—è¡¨ï¼‰
        self.hierarchical_map = {}
        for major_class in self.df[self.major_class_col].unique():
            mask = self.df[self.major_class_col] == major_class
            detail_classes = sorted(
                self.df[mask][self.detail_class_col].unique()
            )
            self.hierarchical_map[major_class] = {
                'major_id': self.major_labels_map[major_class],
                'detail_classes': {
                    det_cat: self.detailed_labels_map[det_cat]
                    for det_cat in detail_classes
                }
            }
        
        logger.info(f"ğŸ“Š å±‚çº§æ˜ å°„:")
        for major_class, info in sorted(self.hierarchical_map.items()):
            logger.info(f"   {info['major_id']}: {major_class}")
            for det_cat, det_id in sorted(info['detail_classes'].items(), key=lambda x: x[1]):
                logger.info(f"      â””â”€ {det_id}: {det_cat}")
        
        # æ·»åŠ æ ‡ç­¾åˆ—åˆ°æ•°æ®æ¡†
        self.df['detail_label'] = self.df[self.detail_class_col].map(
            self.detailed_labels_map
        )
        self.df['major_label'] = self.df[self.major_class_col].map(
            self.major_labels_map
        )
        
        logger.info(f"âœ… ç±»åˆ«æ˜ å°„ç”Ÿæˆå®Œæˆ")
    
    def _transform_crs(self):
        """
        è¿›è¡Œç©ºé—´æŠ•å½±è½¬æ¢
        
        åŠŸèƒ½ï¼š
        1. è‡ªåŠ¨æ£€æµ‹ CSV åæ ‡ç³»ï¼ˆå¦‚æœé…ç½®ä¸º 'auto'ï¼‰
        2. å°†åæ ‡è½¬æ¢ä¸ºç›®æ ‡æŠ•å½±ç³»ç»Ÿ
        3. æ”¯æŒä»»æ„åæ ‡ç³»ï¼ˆä¸ä»…é™äº WGS84ï¼‰
        """
        logger = logging.getLogger(__name__)
        
        # æ­¥éª¤ 1: è‡ªåŠ¨æ£€æµ‹ CSV åæ ‡ç³»
        csv_crs_config = self.config.get('data_specs.spatial.csv_crs', 'auto')
        
        if csv_crs_config == 'auto':
            # è‡ªåŠ¨æ£€æµ‹
            from crs_manager import CRSManager
            crs_manager = CRSManager(self.config)
            detected_crs = crs_manager.auto_detect_csv_crs(
                self.csv_path,
                lon_col=self.lon_col,
                lat_col=self.lat_col
            )
            
            if detected_crs:
                csv_crs = detected_crs
                logger.info(f"âœ… CSV åæ ‡ç³»è‡ªåŠ¨æ£€æµ‹: {csv_crs}")
            else:
                # å›é€€åˆ°é»˜è®¤å€¼
                csv_crs = 'EPSG:4326'
                logger.warning(f"âš ï¸  æ— æ³•è‡ªåŠ¨æ£€æµ‹ï¼Œä½¿ç”¨é»˜è®¤åæ ‡ç³»: {csv_crs}")
        else:
            csv_crs = csv_crs_config
            logger.info(f"ğŸ“ ä½¿ç”¨é…ç½®çš„ CSV åæ ‡ç³»: {csv_crs}")
        
        # æ­¥éª¤ 2: åˆ›å»º GeoDataFrame
        geometry = [
            Point(xy) for xy in zip(self.df[self.lon_col], self.df[self.lat_col])
        ]
        self.gdf = gpd.GeoDataFrame(
            self.df,
            geometry=geometry,
            crs=csv_crs
        )
        
        logger.info(f"âœ… GeoDataFrame åˆ›å»ºå®Œæˆ (åˆå§‹æŠ•å½±: {csv_crs})")
        
        # æ­¥éª¤ 3: è½¬æ¢åˆ°ç›®æ ‡æŠ•å½±
        if csv_crs != self.target_crs:
            try:
                self.gdf = self.gdf.to_crs(self.target_crs)
                logger.info(f"âœ… æŠ•å½±è½¬æ¢å®Œæˆ: {csv_crs} â†’ {self.target_crs}")
            except Exception as e:
                error_msg = f"âŒ æŠ•å½±è½¬æ¢å¤±è´¥: {e}"
                logger.error(error_msg)
                raise ValueError(error_msg)
        else:
            logger.info(f"âœ… CSV åæ ‡ç³»ä¸ç›®æ ‡åæ ‡ç³»ä¸€è‡´ï¼Œæ— éœ€è½¬æ¢")
        
        # æ­¥éª¤ 4: æå–è½¬æ¢åçš„åæ ‡
        self.gdf['x'] = self.gdf.geometry.x
        self.gdf['y'] = self.gdf.geometry.y
        
        logger.info(f"âœ… ç©ºé—´åæ ‡æå–å®Œæˆ")
    
    def _save_maps(self):
        """
        ä¿å­˜æ˜ å°„åˆ° JSON æ–‡ä»¶
        
        ç”Ÿæˆä»¥ä¸‹æ–‡ä»¶ï¼š
        1. detailed_labels_map.json - è¯¦ç»†ç±»åˆ«æ˜ å°„
        2. major_labels_map.json - å¤§ç±»æ˜ å°„
        3. hierarchical_labels_map.json - å±‚çº§æ˜ å°„
        4. labels_summary.json - æ±‡æ€»ä¿¡æ¯
        """
        logger = logging.getLogger(__name__)
        
        # åˆ›å»ºè¾“å‡ºç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # ä¿å­˜è¯¦ç»†ç±»åˆ«æ˜ å°„
        detailed_map_file = self.output_dir / 'detailed_labels_map.json'
        with open(detailed_map_file, 'w', encoding='utf-8') as f:
            json.dump(self.detailed_labels_map, f, ensure_ascii=False, indent=2)
        logger.info(f"ğŸ’¾ è¯¦ç»†ç±»åˆ«æ˜ å°„å·²ä¿å­˜: {detailed_map_file}")
        
        # ä¿å­˜å¤§ç±»æ˜ å°„
        major_map_file = self.output_dir / 'major_labels_map.json'
        with open(major_map_file, 'w', encoding='utf-8') as f:
            json.dump(self.major_labels_map, f, ensure_ascii=False, indent=2)
        logger.info(f"ğŸ’¾ å¤§ç±»æ˜ å°„å·²ä¿å­˜: {major_map_file}")
        
        # ä¿å­˜å±‚çº§æ˜ å°„
        hierarchical_map_file = self.output_dir / 'hierarchical_labels_map.json'
        with open(hierarchical_map_file, 'w', encoding='utf-8') as f:
            json.dump(self.hierarchical_map, f, ensure_ascii=False, indent=2)
        logger.info(f"ğŸ’¾ å±‚çº§æ˜ å°„å·²ä¿å­˜: {hierarchical_map_file}")
        
        # ä¿å­˜æ±‡æ€»ä¿¡æ¯
        summary = {
            'csv_file': str(self.csv_path),
            'total_samples': len(self.df),
            'detailed_classes': {
                'count': len(self.detailed_labels_map),
                'map': self.detailed_labels_map,
            },
            'major_classes': {
                'count': len(self.major_labels_map),
                'map': self.major_labels_map,
            },
            'target_crs': self.target_crs,
            'hierarchy': {
                major: {
                    'major_id': info['major_id'],
                    'detail_count': len(info['detail_classes']),
                    'details': info['detail_classes']
                }
                for major, info in self.hierarchical_map.items()
            }
        }
        
        summary_file = self.output_dir / 'labels_summary.json'
        with open(summary_file, 'w', encoding='utf-8') as f:
            json.dump(summary, f, ensure_ascii=False, indent=2)
        logger.info(f"ğŸ’¾ æ±‡æ€»ä¿¡æ¯å·²ä¿å­˜: {summary_file}")
        
        logger.info(f"âœ… æ‰€æœ‰æ˜ å°„æ–‡ä»¶å·²ä¿å­˜åˆ° {self.output_dir}")
    
    # =========================================================================
    # å…¬å…±æ¥å£æ–¹æ³•
    # =========================================================================
    
    def get_detailed_labels_map(self) -> Dict[str, int]:
        """
        è·å–è¯¦ç»†ç±»åˆ«æ˜ å°„
        
        Returns:
            Dict[str, int]: è¯¦ç»†ç±»åˆ« â†’ æ•°å­—æ ‡ç­¾çš„æ˜ å°„
        
        Example:
            >>> encoder.get_detailed_labels_map()
            {'æ°´ä½“': 0, 'å»ºç­‘': 1, 'å†œä¸š': 2, ...}
        """
        return self.detailed_labels_map.copy()
    
    def get_major_labels_map(self) -> Dict[str, int]:
        """
        è·å–å¤§ç±»æ˜ å°„
        
        Returns:
            Dict[str, int]: å¤§ç±» â†’ æ•°å­—æ ‡ç­¾çš„æ˜ å°„
        
        Example:
            >>> encoder.get_major_labels_map()
            {'æ°´ä½“': 0, 'å»ºç­‘': 1, 'å…¶ä»–': 2}
        """
        return self.major_labels_map.copy()
    
    def get_hierarchical_map(self) -> Dict[str, Dict]:
        """
        è·å–å±‚çº§æ˜ å°„
        
        Returns:
            Dict[str, Dict]: å¤§ç±» â†’ è¯¦ç»†ç±»åˆ«æ˜ å°„çš„å±‚çº§ç»“æ„
        
        Example:
            >>> encoder.get_hierarchical_map()
            {
                'æ°´ä½“': {
                    'major_id': 0,
                    'detail_classes': {'æ²³æµ': 0, 'æ¹–æ³Š': 1, 'æµ·æ´‹': 2}
                },
                ...
            }
        """
        return self.hierarchical_map.copy()
    
    def get_geodataframe(self) -> gpd.GeoDataFrame:
        """
        è·å– GeoDataFrameï¼ˆåŒ…å«åæ ‡ã€æ ‡ç­¾ç­‰ï¼‰
        
        Returns:
            gpd.GeoDataFrame: åŒ…å«å‡ ä½•å’Œæ ‡ç­¾çš„åœ°ç†æ•°æ®æ¡†
        
        Columns:
            - geometry: ç‚¹å‡ ä½•
            - x, y: è½¬æ¢åçš„åæ ‡
            - detail_label: è¯¦ç»†ç±»åˆ«æ ‡ç­¾ï¼ˆæ•°å­—ï¼‰
            - major_label: å¤§ç±»æ ‡ç­¾ï¼ˆæ•°å­—ï¼‰
            - å…¶ä»–åŸå§‹åˆ—...
        """
        return self.gdf.copy()
    
    def get_dataframe(self) -> pd.DataFrame:
        """
        è·å–æ•°æ®æ¡†ï¼ˆä¸åŒ…å«å‡ ä½•ï¼‰
        
        Returns:
            pd.DataFrame: åŒ…å«æ ‡ç­¾ä½†ä¸åŒ…å«å‡ ä½•çš„æ•°æ®æ¡†
        """
        return self.df.copy()
    
    def label_to_category(self, label: int, label_type: str = 'detailed') -> str:
        """
        å°†æ•°å­—æ ‡ç­¾è½¬æ¢å›ç±»åˆ«åç§°
        
        Args:
            label: æ•°å­—æ ‡ç­¾
            label_type: æ ‡ç­¾ç±»å‹ ('detailed' æˆ– 'major')
        
        Returns:
            str: ç±»åˆ«åç§°
        
        Raises:
            ValueError: æ ‡ç­¾ä¸å­˜åœ¨
        
        Example:
            >>> encoder.label_to_category(0, 'detailed')
            'æ°´ä½“'
        """
        if label_type == 'detailed':
            if label not in self.inverse_detailed_map:
                raise ValueError(f"è¯¦ç»†æ ‡ç­¾ {label} ä¸å­˜åœ¨")
            return self.inverse_detailed_map[label]
        elif label_type == 'major':
            if label not in self.inverse_major_map:
                raise ValueError(f"å¤§ç±»æ ‡ç­¾ {label} ä¸å­˜åœ¨")
            return self.inverse_major_map[label]
        else:
            raise ValueError(f"æœªçŸ¥æ ‡ç­¾ç±»å‹: {label_type}")
    
    def category_to_label(self, category: str, category_type: str = 'detailed') -> int:
        """
        å°†ç±»åˆ«åç§°è½¬æ¢ä¸ºæ•°å­—æ ‡ç­¾
        
        Args:
            category: ç±»åˆ«åç§°
            category_type: ç±»åˆ«ç±»å‹ ('detailed' æˆ– 'major')
        
        Returns:
            int: æ•°å­—æ ‡ç­¾
        
        Raises:
            ValueError: ç±»åˆ«ä¸å­˜åœ¨
        
        Example:
            >>> encoder.category_to_label('æ°´ä½“', 'detailed')
            0
        """
        if category_type == 'detailed':
            if category not in self.detailed_labels_map:
                raise ValueError(f"è¯¦ç»†ç±»åˆ« '{category}' ä¸å­˜åœ¨")
            return self.detailed_labels_map[category]
        elif category_type == 'major':
            if category not in self.major_labels_map:
                raise ValueError(f"å¤§ç±» '{category}' ä¸å­˜åœ¨")
            return self.major_labels_map[category]
        else:
            raise ValueError(f"æœªçŸ¥ç±»åˆ«ç±»å‹: {category_type}")
    
    def get_sample_info(self, sample_id: int) -> Dict:
        """
        è·å–å•ä¸ªæ ·æœ¬çš„ä¿¡æ¯
        
        Args:
            sample_id: æ ·æœ¬ ID
        
        Returns:
            Dict: åŒ…å«åæ ‡ã€æ ‡ç­¾ç­‰ä¿¡æ¯çš„å­—å…¸
        
        Raises:
            ValueError: æ ·æœ¬ä¸å­˜åœ¨
        
        Example:
            >>> encoder.get_sample_info(0)
            {
                'id': 0,
                'longitude': 120.5,
                'latitude': 35.2,
                'x': 621234.5,
                'y': 3896234.1,
                'major_class': 'å†œä¸š',
                'detail_class': 'æ°´ç¨»',
                'major_label': 1,
                'detail_label': 5
            }
        """
        row = self.gdf[self.gdf[self.id_col] == sample_id]
        
        if len(row) == 0:
            raise ValueError(f"æ ·æœ¬ ID {sample_id} ä¸å­˜åœ¨")
        
        row = row.iloc[0]
        
        return {
            'id': sample_id,
            'longitude': row[self.lon_col],
            'latitude': row[self.lat_col],
            'x': row['x'],
            'y': row['y'],
            'major_class': row[self.major_class_col],
            'detail_class': row[self.detail_class_col],
            'major_label': int(row['major_label']),
            'detail_label': int(row['detail_label']),
        }
    
    def get_statistics(self) -> Dict:
        """
        è·å–æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            Dict: åŒ…å«æ ·æœ¬æ•°ã€ç±»åˆ«åˆ†å¸ƒç­‰ä¿¡æ¯
        
        Example:
            >>> encoder.get_statistics()
            {
                'total_samples': 100,
                'detailed_class_distribution': {'æ°´ä½“': 20, 'å»ºç­‘': 30, ...},
                'major_class_distribution': {'æ°´ä½“': 20, 'å»ºç­‘': 80},
                'coordinates_stats': {
                    'x': {'min': 620000, 'max': 630000, 'mean': 625000},
                    'y': {'min': 3890000, 'max': 3900000, 'mean': 3895000}
                }
            }
        """
        detailed_dist = self.df[self.detail_class_col].value_counts().to_dict()
        major_dist = self.df[self.major_class_col].value_counts().to_dict()
        
        coords_stats = {
            'x': {
                'min': float(self.gdf['x'].min()),
                'max': float(self.gdf['x'].max()),
                'mean': float(self.gdf['x'].mean()),
                'std': float(self.gdf['x'].std()),
            },
            'y': {
                'min': float(self.gdf['y'].min()),
                'max': float(self.gdf['y'].max()),
                'mean': float(self.gdf['y'].mean()),
                'std': float(self.gdf['y'].std()),
            }
        }
        
        return {
            'total_samples': len(self.df),
            'detailed_class_distribution': detailed_dist,
            'major_class_distribution': major_dist,
            'coordinates_stats': coords_stats,
        }
    
    def save_geodataframe(self, filepath: Path = None, format: str = 'geojson'):
        """
        ä¿å­˜ GeoDataFrame åˆ°æ–‡ä»¶
        
        Args:
            filepath: è¾“å‡ºæ–‡ä»¶è·¯å¾„ã€‚å¦‚æœä¸º Noneï¼Œåˆ™ä¿å­˜åˆ°å®éªŒç›®å½•
            format: è¾“å‡ºæ ¼å¼ ('geojson', 'shapefile', 'geopackage')
        
        Example:
            >>> encoder.save_geodataframe(format='geojson')
            # ä¿å­˜åˆ° {output_dir}/labels_geodata.geojson
        """
        logger = logging.getLogger(__name__)
        
        if filepath is None:
            if format == 'geojson':
                filepath = self.output_dir / 'labels_geodata.geojson'
            elif format == 'shapefile':
                filepath = self.output_dir / 'labels_geodata.shp'
            elif format == 'geopackage':
                filepath = self.output_dir / 'labels_geodata.gpkg'
            else:
                raise ValueError(f"æœªçŸ¥æ ¼å¼: {format}")
        
        filepath = Path(filepath)
        filepath.parent.mkdir(parents=True, exist_ok=True)
        
        try:
            if format == 'geojson':
                self.gdf.to_file(filepath, driver='GeoJSON', encoding='utf-8')
            elif format == 'shapefile':
                self.gdf.to_file(filepath, driver='ESRI Shapefile', encoding='utf-8')
            elif format == 'geopackage':
                self.gdf.to_file(filepath, driver='GPKG')
            
            logger.info(f"ğŸ’¾ GeoDataFrame å·²ä¿å­˜: {filepath}")
        except Exception as e:
            error_msg = f"âŒ ä¿å­˜ GeoDataFrame å¤±è´¥: {e}"
            logger.error(error_msg)
            raise IOError(error_msg)
    
    def __repr__(self) -> str:
        """å­—ç¬¦ä¸²è¡¨ç¤º"""
        return (
            f"LabelEncoder(\n"
            f"  csv_path={self.csv_path},\n"
            f"  output_dir={self.output_dir},\n"
            f"  target_crs={self.target_crs},\n"
            f"  total_samples={len(self.df)},\n"
            f"  detailed_classes={len(self.detailed_labels_map)},\n"
            f"  major_classes={len(self.major_labels_map)}\n"
            f")"
        )


# ============================================================================
# ä½¿ç”¨ç¤ºä¾‹å’Œæµ‹è¯•
# ============================================================================

if __name__ == "__main__":
    try:
        # åˆå§‹åŒ–é…ç½®ç®¡ç†å™¨
        from config_manager import ConfigManager
        
        print("=" * 80)
        print("LabelEncoder ä½¿ç”¨ç¤ºä¾‹")
        print("=" * 80)
        
        config = ConfigManager('./config.yaml')
        
        # åˆå§‹åŒ–æ ‡ç­¾ç¼–ç å™¨
        print("\n1ï¸âƒ£  åˆå§‹åŒ– LabelEncoder...")
        encoder = LabelEncoder(config=config)
        print(f"\n{encoder}\n")
        
        # è·å–æ˜ å°„
        print("2ï¸âƒ£  è·å–ç±»åˆ«æ˜ å°„...")
        detailed_map = encoder.get_detailed_labels_map()
        major_map = encoder.get_major_labels_map()
        print(f"\nè¯¦ç»†ç±»åˆ«æ˜ å°„ ({len(detailed_map)} ç±»):")
        for cat, label in sorted(detailed_map.items(), key=lambda x: x[1]):
            print(f"   {label}: {cat}")
        
        print(f"\nå¤§ç±»æ˜ å°„ ({len(major_map)} ç±»):")
        for cat, label in sorted(major_map.items(), key=lambda x: x[1]):
            print(f"   {label}: {cat}")
        
        # è·å–å±‚çº§æ˜ å°„
        print("\n3ï¸âƒ£  è·å–å±‚çº§æ˜ å°„...")
        hierarchical_map = encoder.get_hierarchical_map()
        print(f"\nå±‚çº§æ˜ å°„ç»“æ„:")
        for major_class, info in sorted(hierarchical_map.items()):
            print(f"   {info['major_id']}: {major_class}")
            for det_cat, det_id in sorted(info['detail_classes'].items(), key=lambda x: x[1]):
                print(f"      â””â”€ {det_id}: {det_cat}")
        
        # è·å– GeoDataFrame
        print("\n4ï¸âƒ£  è·å– GeoDataFrame...")
        gdf = encoder.get_geodataframe()
        print(f"\nGeoDataFrame ä¿¡æ¯:")
        print(f"   è¡Œæ•°: {len(gdf)}")
        print(f"   åˆ—æ•°: {len(gdf.columns)}")
        print(f"   æŠ•å½±: {gdf.crs}")
        print(f"\nå‰ 3 è¡Œ:")
        print(gdf[['x', 'y', 'detail_label', 'major_label']].head(3))
        
        # è·å–æ ·æœ¬ä¿¡æ¯
        print("\n5ï¸âƒ£  è·å–æ ·æœ¬ä¿¡æ¯...")
        sample_info = encoder.get_sample_info(1)
        print(f"\næ ·æœ¬ 1 ä¿¡æ¯:")
        for key, value in sample_info.items():
            print(f"   {key}: {value}")
        
        # æ ‡ç­¾è½¬æ¢
        print("\n6ï¸âƒ£  æ ‡ç­¾è½¬æ¢...")
        print(f"   æ ‡ç­¾ 0 (è¯¦ç»†) â†’ {encoder.label_to_category(0, 'detailed')}")
        print(f"   'æ°´ä½“' (è¯¦ç»†) â†’ {encoder.category_to_label('æ°´ä½“', 'detailed')}")
        
        # è·å–ç»Ÿè®¡ä¿¡æ¯
        print("\n7ï¸âƒ£  è·å–ç»Ÿè®¡ä¿¡æ¯...")
        stats = encoder.get_statistics()
        print(f"\næ ·æœ¬ç»Ÿè®¡:")
        print(f"   æ€»æ ·æœ¬æ•°: {stats['total_samples']}")
        print(f"   è¯¦ç»†ç±»åˆ«åˆ†å¸ƒ: {stats['detailed_class_distribution']}")
        print(f"   å¤§ç±»åˆ†å¸ƒ: {stats['major_class_distribution']}")
        
        # ä¿å­˜ GeoDataFrame
        print("\n8ï¸âƒ£  ä¿å­˜ GeoDataFrame...")
        encoder.save_geodataframe(format='geojson')
        print(f"âœ… GeoDataFrame å·²ä¿å­˜")
        
        print("\n" + "=" * 80)
        print("âœ… æ‰€æœ‰ç¤ºä¾‹å®Œæˆ!")
        print("=" * 80 + "\n")
        
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
