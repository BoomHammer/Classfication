#!/usr/bin/env python3
"""
train.py: è®­ç»ƒä¸»ç¨‹åº (ä¿®å¤ç‰ˆ - è‡ªåŠ¨æƒé‡ä¸å‚æ•°)
"""

import sys
import json
import argparse
from pathlib import Path
import torch
import numpy as np
from torch.utils.data import DataLoader
from collections import Counter

sys.path.insert(0, str(Path(__file__).parent))
from config_manager import ConfigManager
from point_timeseries_dataset import PointTimeSeriesDataset, collate_fn
from model_architecture import DualStreamSpatio_TemporalFusionNetwork
from trainer import Trainer

def calculate_class_weights(dataset, num_classes):
    """è®¡ç®—ç±»åˆ«æƒé‡ (Inverse Frequency)"""
    print("âš–ï¸ æ­£åœ¨è®¡ç®—ç±»åˆ«æƒé‡...")
    # ä» Dataset çš„ points_df ä¸­ç›´æ¥è·å–æ ‡ç­¾åˆ—
    # æ³¨æ„ï¼šlabel å­—æ®µåå–å†³äº Dataset åˆå§‹åŒ–æ—¶è®¾å®šçš„ target_col
    # è¿™é‡Œå‡è®¾æˆ‘ä»¬è®­ç»ƒçš„æ˜¯ dataset.label_col æŒ‡å®šçš„åˆ—
    all_labels = []
    # ç¨å¾® trick ä¸€ä¸‹ï¼šDataset å·²ç»æŠŠ df å­˜åœ¨ self.points_df
    # æˆ‘ä»¬æ ¹æ® split ç­›é€‰
    indices = dataset.indices
    # dataset.points_df æ˜¯å®Œæ•´çš„ dataframe
    # indices æ˜¯ numpy array
    subset_df = dataset.points_df.iloc[indices]
    
    # ç¡®å®šå½“å‰è®­ç»ƒçš„ç›®æ ‡åˆ— (major æˆ– detail)
    # æˆ‘ä»¬å¯ä»¥é€šè¿‡è¯»å–ç¬¬ä¸€ä¸ªæ ·æœ¬çš„ 'label' æ¥ç¡®è®¤ï¼Œæˆ–è€…å‡è®¾æ˜¯ detail
    # ä½†ä¸ºäº†ç¨³å¥ï¼Œæˆ‘ä»¬ç»Ÿè®¡ dataset[i]['label']
    # ä¸ºäº†é€Ÿåº¦ï¼Œç›´æ¥ç”¨ DataFrame
    # å‡è®¾ Dataset æ­£ç¡®è®¾ç½®äº†å½“å‰ä»»åŠ¡çš„æ ‡ç­¾
    
    # ç®€æ˜“æ–¹æ¡ˆï¼šéå† dataset (ç¨å¾®æ…¢ç‚¹ä½†ç¨³)
    # æˆ–è€…ç›´æ¥ç”¨ DataFrame çš„åˆ†å¸ƒ
    counts = Counter()
    # å‡è®¾ points_df é‡Œçš„åˆ—æ˜¯ encoder å¤„ç†è¿‡çš„
    # è¿™é‡Œæˆ‘ä»¬åªå–å‰ 1000 ä¸ªæ ·æœ¬åšä¼°è®¡ï¼Œæˆ–è€…å…¨éƒ¨
    labels = [dataset[i]['label'].item() for i in range(len(dataset))]
    counts.update(labels)
    
    total = sum(counts.values())
    weights = torch.zeros(num_classes)
    for cls_idx in range(num_classes):
        count = counts[cls_idx]
        if count > 0:
            weights[cls_idx] = total / (len(counts) * count)
        else:
            weights[cls_idx] = 1.0 # æ²¡å‡ºç°çš„ç±»ç»™ 1
            
    print(f"   ç±»åˆ«åˆ†å¸ƒ: {dict(counts)}")
    print(f"   è®¡ç®—æƒé‡: {weights.numpy().round(3)}")
    return weights

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--epochs', type=int, default=50)
    parser.add_argument('--lr', type=float, default=1e-3)
    parser.add_argument('--batch_size', type=int, default=32) # é»˜è®¤ä¸º 32
    parser.add_argument('--accum_steps', type=int, default=2) # é»˜è®¤ç´¯ç§¯2æ­¥ -> æ•ˆèƒ½64
    parser.add_argument('--config', type=str, default='config.yaml')
    parser.add_argument('--debug', action='store_true')
    args = parser.parse_args()

    # 1. é…ç½®
    config_path = Path(__file__).parent / args.config
    config = ConfigManager(str(config_path))
    output_dir = config.get_experiment_output_dir()
    
    # 2. è‡ªåŠ¨æ£€æµ‹å‚æ•°
    param_file = output_dir / 'detected_parameters.json'
    if not param_file.exists():
        print("âŒ è¯·å…ˆè¿è¡Œ preprocess_dataset.py")
        return
    with open(param_file, 'r') as f:
        params = json.load(f)
    
    # 3. æ•°æ®é›†
    print("ğŸ“Š åŠ è½½æ•°æ®é›†...")
    train_ds = PointTimeSeriesDataset(config, None, split='train', split_ratio=[0.7, 0.15, 0.15])
    val_ds = PointTimeSeriesDataset(config, None, split='val', split_ratio=[0.7, 0.15, 0.15])
    test_ds = PointTimeSeriesDataset(config, None, split='test', split_ratio=[0.7, 0.15, 0.15])
    
    train_loader = DataLoader(train_ds, batch_size=args.batch_size, shuffle=True, collate_fn=collate_fn, num_workers=8)
    val_loader = DataLoader(val_ds, batch_size=args.batch_size, shuffle=False, collate_fn=collate_fn, num_workers=4)
    test_loader = DataLoader(test_ds, batch_size=args.batch_size, shuffle=False, collate_fn=collate_fn, num_workers=4)

    # 4. è®¡ç®—æƒé‡
    class_weights = calculate_class_weights(train_ds, params['num_classes'])

    # 5. æ¨¡å‹
    print(f"ğŸ—ï¸ æ„å»ºæ¨¡å‹ (Dynamic: {params['dynamic_channels']}, Static: {params['static_channels']})...")
    model = DualStreamSpatio_TemporalFusionNetwork(
        in_channels_dynamic=params['dynamic_channels'],
        in_channels_static=params['static_channels'],
        num_classes=params['num_classes'],
        hidden_dim=config.get('model.hidden_dim', 64),
        dropout=config.get('model.dropout', 0.2)
    )

    # 6. è®­ç»ƒ
    trainer = Trainer(
        model=model,
        train_dataloader=train_loader,
        val_dataloader=val_loader,
        test_dataloader=test_loader,
        num_classes=params['num_classes'],
        class_weights=class_weights, # ä¼ å…¥æƒé‡
        output_dir=output_dir
    )
    
    trainer.train(
        num_epochs=args.epochs,
        learning_rate=args.lr,
        accumulation_steps=args.accum_steps, # ä¼ å…¥ç´¯ç§¯æ­¥æ•°
        debug=args.debug
    )
    
    trainer.test()

if __name__ == '__main__':
    main()