"""
RasterCrawler: é¥æ„Ÿå½±åƒæ–‡ä»¶çˆ¬è™«æ¨¡å—

åŠŸèƒ½ï¼š
1. é€’å½’æ‰«æå½±åƒæ–‡ä»¶å¤¹
2. æ­£åˆ™è§£ææ–‡ä»¶åæå–æ—¶é—´ä¿¡æ¯
3. æ‡’åŠ è½½æå–ç©ºé—´å…ƒæ•°æ®ï¼ˆè¾¹ç•Œæ¡†ã€æŠ•å½±ï¼‰
4. æ„å»º R-æ ‘ç´¢å¼•ä»¥åŠ é€Ÿç©ºé—´æŸ¥è¯¢
5. å¿«é€ŸæŸ¥æ‰¾ç‚¹æ‰€åœ¨çš„å½±åƒæ–‡ä»¶
"""

import re
import json
import logging
import sys
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Tuple, Optional, Pattern
from dataclasses import dataclass, asdict
from rtree import index

import rasterio
from rasterio.io import MemoryFile
import numpy as np
import pandas as pd


@dataclass
class RasterMetadata:
    """æ …æ ¼å…ƒæ•°æ®"""
    filepath: Path
    filename: str
    bounds: Tuple[float, float, float, float]  # (left, bottom, right, top)
    crs: str
    width: int
    height: int
    resolution: Tuple[float, float]  # (x_res, y_res)
    date: Optional[datetime] = None
    year: Optional[int] = None
    month: Optional[int] = None
    extra_fields: Optional[Dict] = None
    
    def __post_init__(self):
        """æ•°æ®éªŒè¯"""
        if len(self.bounds) != 4:
            raise ValueError(f"bounds å¿…é¡»æ˜¯ 4 å…ƒç»„ï¼Œå¾—åˆ°: {self.bounds}")
        if not isinstance(self.filepath, Path):
            self.filepath = Path(self.filepath)
    
    def to_dict(self) -> Dict:
        """è½¬æ¢ä¸ºå­—å…¸"""
        d = asdict(self)
        d['filepath'] = str(self.filepath)
        d['bounds'] = list(self.bounds)
        d['resolution'] = list(self.resolution)
        d['date'] = self.date.isoformat() if self.date else None
        return d
    
    def contains_point(self, x: float, y: float) -> bool:
        """æ£€æŸ¥ç‚¹æ˜¯å¦åœ¨æ …æ ¼è¾¹ç•Œå†…"""
        left, bottom, right, top = self.bounds
        return left <= x <= right and bottom <= y <= top


class RasterCrawler:
    """
    é¥æ„Ÿå½±åƒçˆ¬è™«ç±»
    
    åŠŸèƒ½ï¼š
    1. é€’å½’æ‰«æå½±åƒæ–‡ä»¶å¤¹
    2. ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼è§£ææ–‡ä»¶å
    3. æ‡’åŠ è½½æå–ç©ºé—´å…ƒæ•°æ®
    4. æ„å»º R-æ ‘ç´¢å¼•
    5. å¿«é€Ÿç©ºé—´æŸ¥è¯¢
    
    ä½¿ç”¨ç¤ºä¾‹ï¼š
        crawler = RasterCrawler(
            config=config,
            raster_dir='./data/raster/dynamic/',
            filename_pattern=r'S2_(?P<year>\d{4})_(?P<month>\d{2})_.*'
        )
        
        # è·å–æ‰€æœ‰æ …æ ¼
        rasters = crawler.get_all_rasters()
        
        # æŸ¥æ‰¾åŒ…å«ç‚¹çš„æ …æ ¼
        point_rasters = crawler.find_rasters_by_point(120.5, 35.2)
    """
    
    def __init__(
        self,
        config: 'ConfigManager',
        raster_dir: Optional[Path] = None,
        filename_pattern: Optional[str] = None,
        file_extensions: Tuple[str, ...] = ('.tif', '.tiff', '.jp2'),
        date_format: Optional[str] = None,
    ):
        """
        åˆå§‹åŒ– RasterCrawler
        
        Args:
            config: ConfigManager å¯¹è±¡
            raster_dir: å½±åƒç›®å½•è·¯å¾„ã€‚å¦‚æœä¸º Noneï¼Œåˆ™ä» config è¯»å–
            filename_pattern: æ–‡ä»¶åæ­£åˆ™è¡¨è¾¾å¼ã€‚åŒ…å«å‘½åç»„å¦‚ (?P<year>...), (?P<month>...)
            file_extensions: è¦æ‰«æçš„æ–‡ä»¶æ‰©å±•å
            date_format: æ—¥æœŸæ ¼å¼å­—ç¬¦ä¸²ï¼ˆå¦‚ '%Y-%m-%d'ï¼‰
        
        Raises:
            FileNotFoundError: å½±åƒç›®å½•ä¸å­˜åœ¨
            ValueError: æ–‡ä»¶åæ­£åˆ™è¡¨è¾¾å¼æ— æ•ˆ
        """
        self._setup_logging()
        logger = logging.getLogger(__name__)
        
        # ä¿å­˜é…ç½®
        self.config = config
        self.raster_dir = Path(raster_dir) if raster_dir else config.get_resolved_path('dynamic_images_dir')
        self.output_dir = config.get_experiment_output_dir()
        self.file_extensions = file_extensions
        self.date_format = date_format
        
        logger.info(f"ğŸ“‚ å½±åƒç›®å½•: {self.raster_dir}")
        logger.info(f"ğŸ“‚ è¾“å‡ºç›®å½•: {self.output_dir}")
        
        # éªŒè¯ç›®å½•å­˜åœ¨
        if not self.raster_dir.exists():
            error_msg = f"âŒ å½±åƒç›®å½•ä¸å­˜åœ¨: {self.raster_dir}"
            logger.error(error_msg)
            raise FileNotFoundError(error_msg)
        
        # ç¼–è¯‘æ­£åˆ™è¡¨è¾¾å¼
        if filename_pattern:
            try:
                self.filename_pattern = re.compile(filename_pattern)
                logger.info(f"âœ… æ­£åˆ™è¡¨è¾¾å¼å·²ç¼–è¯‘: {filename_pattern}")
            except re.error as e:
                error_msg = f"âŒ æ­£åˆ™è¡¨è¾¾å¼æ— æ•ˆ: {e}"
                logger.error(error_msg)
                raise ValueError(error_msg)
        else:
            self.filename_pattern = None
            logger.info("âš ï¸  æœªæŒ‡å®šæ–‡ä»¶åæ­£åˆ™è¡¨è¾¾å¼ï¼Œå°†ä¸è¿›è¡Œæ—¶é—´è§£æ")
        
        # åˆå§‹åŒ–æ•°æ®å­˜å‚¨
        self.rasters_metadata: Dict[str, RasterMetadata] = {}  # filepath â†’ metadata
        self.rtree_index: Optional[index.Index] = None
        self.raster_list: List[RasterMetadata] = []
        
        # æ‰«æå¹¶ç´¢å¼•
        logger.info("ğŸ” å¼€å§‹æ‰«æå½±åƒæ–‡ä»¶...")
        self._scan_rasters()
        logger.info(f"âœ… å‘ç° {len(self.rasters_metadata)} ä¸ªå½±åƒæ–‡ä»¶")
        
        # æ„å»º R-æ ‘ç´¢å¼•
        logger.info("ğŸŒ³ å¼€å§‹æ„å»º R-æ ‘ç´¢å¼•...")
        self._build_rtree_index()
        logger.info(f"âœ… R-æ ‘ç´¢å¼•æ„å»ºå®Œæˆ")
        
        # ä¿å­˜å…ƒæ•°æ®
        logger.info("ğŸ’¾ ä¿å­˜å…ƒæ•°æ®...")
        self._save_metadata()
        logger.info("âœ… å…ƒæ•°æ®å·²ä¿å­˜")
    
    @staticmethod
    def _setup_logging():
        """é…ç½®æ—¥å¿—ç³»ç»Ÿ"""
        if not logging.getLogger(__name__).handlers:
            handler = logging.StreamHandler(sys.stdout)
            formatter = logging.Formatter(
                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
            )
            handler.setFormatter(formatter)
            logging.getLogger(__name__).addHandler(handler)
            logging.getLogger(__name__).setLevel(logging.INFO)
    
    def _scan_rasters(self):
        """
        é€’å½’æ‰«æå½±åƒæ–‡ä»¶
        
        æ‡’åŠ è½½ç­–ç•¥ï¼šä»…è¯»å–æ–‡ä»¶å…ƒæ•°æ®ï¼Œä¸è¯»å–åƒç´ æ•°æ®
        """
        logger = logging.getLogger(__name__)
        
        raster_files = []
        
        # é€’å½’æœç´¢
        for ext in self.file_extensions:
            raster_files.extend(self.raster_dir.rglob(f'*{ext}'))
        
        if not raster_files:
            logger.warning(f"âš ï¸  æœªæ‰¾åˆ°å½±åƒæ–‡ä»¶")
            return
        
        logger.info(f"ğŸ“ æ‰¾åˆ° {len(raster_files)} ä¸ªå½±åƒæ–‡ä»¶")
        
        # å¤„ç†æ¯ä¸ªæ–‡ä»¶
        for filepath in raster_files:
            try:
                metadata = self._extract_metadata(filepath)
                self.rasters_metadata[str(filepath)] = metadata
                self.raster_list.append(metadata)
            except Exception as e:
                logger.warning(f"âš ï¸  è·³è¿‡æ— æ•ˆæ–‡ä»¶ {filepath}: {str(e)[:100]}")
    
    def _extract_metadata(self, filepath: Path) -> RasterMetadata:
        """
        æå–å•ä¸ªæ …æ ¼çš„å…ƒæ•°æ®
        
        ä½¿ç”¨æ‡’åŠ è½½ï¼ˆLazy Loadingï¼‰ç­–ç•¥ï¼Œä»…è¯»å–å…ƒæ•°æ®ï¼Œä¸è¯»å–åƒç´ æ•°æ®
        
        Args:
            filepath: æ …æ ¼æ–‡ä»¶è·¯å¾„
        
        Returns:
            RasterMetadata: æ …æ ¼å…ƒæ•°æ®å¯¹è±¡
        """
        logger = logging.getLogger(__name__)
        
        # ä½¿ç”¨ rasterio è¯»å–å…ƒæ•°æ®
        try:
            with rasterio.open(filepath) as src:
                bounds = src.bounds
                crs = src.crs
                width = src.width
                height = src.height
                transform = src.transform
                
                # è®¡ç®—åˆ†è¾¨ç‡ï¼ˆä» transform ä¸­æå–ï¼‰
                x_res = abs(transform.a)
                y_res = abs(transform.e)
                resolution = (x_res, y_res)
        except Exception as e:
            logger.warning(f"âš ï¸  æ— æ³•è¯»å–æ …æ ¼æ–‡ä»¶å…ƒæ•°æ®: {filepath}")
            logger.warning(f"   é”™è¯¯: {e}")
            raise ValueError(f"æ— æ³•è¯»å–æ …æ ¼å…ƒæ•°æ®: {e}") from e
        
        # è§£ææ–‡ä»¶å
        filename = filepath.name
        date = None
        year = None
        month = None
        extra_fields = {}
        
        # ä½¿ç”¨æ™ºèƒ½æ—¶é—´è§£æï¼ˆæ”¯æŒå¯å˜é•¿åº¦å‰ç¼€ï¼‰
        try:
            from time_parser import extract_time_from_filename
            date, year, month, data_type = extract_time_from_filename(filename)
            if data_type:
                extra_fields['data_type'] = data_type
        except ImportError:
            logger.debug("âš ï¸  time_parser æ¨¡å—ä¸å¯ç”¨ï¼Œä½¿ç”¨å¤‡ç”¨è§£ææ–¹æ³•")
            # å¤‡ç”¨æ–¹æ³•ï¼šä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ï¼ˆå¦‚æœé…ç½®äº†çš„è¯ï¼‰
            if self.filename_pattern:
                match = self.filename_pattern.match(filename)
                if match:
                    groups = match.groupdict()
                    
                    # æå–å¹´æœˆä¿¡æ¯
                    if 'year' in groups:
                        year = int(groups.pop('year'))
                    if 'month' in groups:
                        month = int(groups.pop('month'))
                    
                    # æ„é€ æ—¥æœŸå¯¹è±¡
                    if year is not None:
                        try:
                            day = int(groups.pop('day', 1))
                            date = datetime(year, month or 1, day)
                        except (ValueError, TypeError):
                            date = None
                    
                    # ä¿å­˜å…¶ä»–å­—æ®µ
                    extra_fields = {k: v for k, v in groups.items() if v is not None}
        except Exception as e:
            logger.debug(f"âš ï¸  æ—¶é—´è§£æå¤±è´¥: {e}")
        
        logger.debug(f"âœ“ {filename}: bounds={bounds}, crs={crs}, date={date}, year={year}, month={month}")
        
        return RasterMetadata(
            filepath=filepath,
            filename=filename,
            bounds=bounds,
            crs=str(crs) if crs else 'UNKNOWN',
            width=width,
            height=height,
            resolution=resolution,
            date=date,
            year=year,
            month=month,
            extra_fields=extra_fields if extra_fields else None
        )
    
    def _build_rtree_index(self):
        """
        æ„å»º R-æ ‘ç´¢å¼•
        
        ç”¨äºåŠ é€Ÿç©ºé—´æŸ¥è¯¢ã€‚å¤æ‚åº¦ä» O(N) é™è‡³ O(log N)ã€‚
        """
        logger = logging.getLogger(__name__)
        
        # åˆ›å»º R-æ ‘ç´¢å¼•ï¼ˆä½¿ç”¨ interleaved=Trueï¼‰
        # interleaved=True è¡¨ç¤ºåæ ‡æ ¼å¼ä¸º (minx, miny, maxx, maxy)
        # interleaved=False éœ€è¦ (minx, maxx, miny, maxy) æ ¼å¼ï¼Œå®¹æ˜“å‡ºé”™
        self.rtree_index = index.Index(interleaved=True)
        
        # ä¸ºæ¯ä¸ªæ …æ ¼æ·»åŠ è¾¹ç•Œæ¡†åˆ°ç´¢å¼•
        valid_count = 0
        invalid_count = 0
        
        for idx, metadata in enumerate(self.raster_list):
            try:
                left, bottom, right, top = metadata.bounds
                
                # éªŒè¯è¾¹ç•Œæ¡†çš„æœ‰æ•ˆæ€§
                if left >= right or bottom >= top:
                    logger.warning(f"âš ï¸  æ— æ•ˆçš„è¾¹ç•Œæ¡†: {metadata.filename}")
                    logger.warning(f"   bounds: ({left}, {bottom}, {right}, {top})")
                    invalid_count += 1
                    continue
                
                # R-æ ‘ insert æ ¼å¼ (interleaved=True): (id, (minx, miny, maxx, maxy), object)
                self.rtree_index.insert(
                    valid_count,
                    (left, bottom, right, top),
                    obj=metadata
                )
                valid_count += 1
            except Exception as e:
                logger.warning(f"âš ï¸  æ— æ³•æ·»åŠ æ …æ ¼åˆ°ç´¢å¼•: {metadata.filename}")
                logger.warning(f"   é”™è¯¯: {e}")
                invalid_count += 1
        
        logger.info(f"âœ… R-æ ‘ç´¢å¼•å·²æ„å»º ({valid_count} ä¸ªæ¡ç›®)")
        if invalid_count > 0:
            logger.warning(f"âš ï¸  è·³è¿‡äº† {invalid_count} ä¸ªæ— æ•ˆæ …æ ¼")
    
    def _save_metadata(self):
        """
        ä¿å­˜æ …æ ¼å…ƒæ•°æ®åˆ° JSON æ–‡ä»¶
        
        ç”Ÿæˆä»¥ä¸‹æ–‡ä»¶ï¼š
        1. rasters_metadata.json - æ‰€æœ‰æ …æ ¼çš„è¯¦ç»†å…ƒæ•°æ®
        2. rasters_summary.json - æ±‡æ€»ç»Ÿè®¡ä¿¡æ¯
        """
        logger = logging.getLogger(__name__)
        
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # ä¿å­˜è¯¦ç»†å…ƒæ•°æ®
        metadata_file = self.output_dir / 'rasters_metadata.json'
        metadata_list = [m.to_dict() for m in self.raster_list]
        
        with open(metadata_file, 'w', encoding='utf-8') as f:
            json.dump(metadata_list, f, ensure_ascii=False, indent=2, default=str)
        logger.info(f"ğŸ’¾ æ …æ ¼å…ƒæ•°æ®å·²ä¿å­˜: {metadata_file}")
        
        # ä¿å­˜æ±‡æ€»ä¿¡æ¯
        summary_file = self.output_dir / 'rasters_summary.json'
        
        # ç»Ÿè®¡æ—¶é—´è¦†ç›–èŒƒå›´
        dates = [m.date for m in self.raster_list if m.date]
        date_range = None
        if dates:
            dates_sorted = sorted(dates)
            date_range = {
                'start_date': dates_sorted[0].isoformat(),
                'end_date': dates_sorted[-1].isoformat(),
                'date_count': len(set([d.date() for d in dates]))
            }
        
        # ç»Ÿè®¡ç©ºé—´èŒƒå›´
        if self.raster_list:
            all_bounds = [m.bounds for m in self.raster_list]
            all_lefts = [b[0] for b in all_bounds]
            all_bottoms = [b[1] for b in all_bounds]
            all_rights = [b[2] for b in all_bounds]
            all_tops = [b[3] for b in all_bounds]
            
            spatial_range = {
                'min_x': min(all_lefts),
                'min_y': min(all_bottoms),
                'max_x': max(all_rights),
                'max_y': max(all_tops),
            }
        else:
            spatial_range = None
        
        # ç»Ÿè®¡æŠ•å½±
        crs_counts = {}
        for m in self.raster_list:
            crs_counts[m.crs] = crs_counts.get(m.crs, 0) + 1
        
        summary = {
            'total_rasters': len(self.raster_list),
            'raster_dir': str(self.raster_dir),
            'date_range': date_range,
            'spatial_range': spatial_range,
            'crs_distribution': crs_counts,
            'file_extensions': self.file_extensions,
        }
        
        with open(summary_file, 'w', encoding='utf-8') as f:
            json.dump(summary, f, ensure_ascii=False, indent=2)
        logger.info(f"ğŸ’¾ æ±‡æ€»ä¿¡æ¯å·²ä¿å­˜: {summary_file}")
    
    # =========================================================================
    # å…¬å…±æ¥å£æ–¹æ³•
    # =========================================================================
    
    def get_all_rasters(self) -> List[RasterMetadata]:
        """
        è·å–æ‰€æœ‰æ …æ ¼å…ƒæ•°æ®
        
        Returns:
            List[RasterMetadata]: æ‰€æœ‰æ …æ ¼çš„å…ƒæ•°æ®åˆ—è¡¨
        """
        return [m for m in self.raster_list]
    
    def get_raster_count(self) -> int:
        """
        è·å–æ …æ ¼æ€»æ•°
        
        Returns:
            int: æ …æ ¼æ•°é‡
        """
        return len(self.raster_list)
    
    def find_rasters_by_point(
        self,
        x: float,
        y: float,
        return_count: bool = False
    ) -> List[RasterMetadata]:
        """
        ä½¿ç”¨ R-æ ‘ç´¢å¼•å¿«é€ŸæŸ¥æ‰¾åŒ…å«æŒ‡å®šç‚¹çš„æ …æ ¼
        
        æ—¶é—´å¤æ‚åº¦ï¼šO(log N)ï¼Œå…¶ä¸­ N ä¸ºæ …æ ¼æ€»æ•°
        
        Args:
            x: ç‚¹çš„ X åæ ‡
            y: ç‚¹çš„ Y åæ ‡
            return_count: æ˜¯å¦è¿”å›è®¡æ•°è€Œä¸æ˜¯å¯¹è±¡åˆ—è¡¨
        
        Returns:
            List[RasterMetadata]: åŒ…å«è¯¥ç‚¹çš„æ …æ ¼åˆ—è¡¨ï¼ˆå·²æ’åºæŒ‰æ—¶é—´ï¼‰
        
        Example:
            >>> crawlers = crawler.find_rasters_by_point(120.5, 35.2)
            >>> print(f"æ‰¾åˆ° {len(rasters)} ä¸ªåŒ…å«è¯¥ç‚¹çš„æ …æ ¼")
        """
        logger = logging.getLogger(__name__)
        
        if self.rtree_index is None:
            logger.error("âŒ R-æ ‘ç´¢å¼•æœªåˆå§‹åŒ–")
            return []
        
        # æŸ¥è¯¢ R-æ ‘ï¼šæ‰¾åˆ°è¾¹ç•Œæ¡†åŒ…å«è¯¥ç‚¹çš„æ‰€æœ‰æ …æ ¼
        # æŸ¥è¯¢ç‚¹ä¸º (x, y, x, y) - ä¸€ä¸ªç‚¹çš„è¾¹ç•Œæ¡†
        hits = list(self.rtree_index.intersection((x, y, x, y), objects=True))
        
        # è·å–å‘½ä¸­çš„å…ƒæ•°æ®
        rasters = []
        for hit in hits:
            metadata = hit.object
            # ç²¾ç¡®æ£€æŸ¥ï¼šç¡®è®¤ç‚¹ç¡®å®åœ¨æ …æ ¼å†…
            if metadata.contains_point(x, y):
                rasters.append(metadata)
        
        # æŒ‰æ—¥æœŸæ’åº
        rasters.sort(key=lambda m: m.date if m.date else datetime.min)
        
        if return_count:
            return len(rasters)
        
        logger.debug(f"âœ“ ç‚¹ ({x}, {y}) åŒ…å«åœ¨ {len(rasters)} ä¸ªæ …æ ¼ä¸­")
        return rasters
    
    def find_rasters_by_bounds(
        self,
        min_x: float,
        min_y: float,
        max_x: float,
        max_y: float,
    ) -> List[RasterMetadata]:
        """
        ä½¿ç”¨ R-æ ‘ç´¢å¼•æŸ¥æ‰¾ä¸æŒ‡å®šè¾¹ç•Œæ¡†ç›¸äº¤çš„æ …æ ¼
        
        Args:
            min_x, min_y, max_x, max_y: è¾¹ç•Œæ¡†åæ ‡
        
        Returns:
            List[RasterMetadata]: ä¸è¾¹ç•Œæ¡†ç›¸äº¤çš„æ …æ ¼åˆ—è¡¨
        """
        logger = logging.getLogger(__name__)
        
        if self.rtree_index is None:
            logger.error("âŒ R-æ ‘ç´¢å¼•æœªåˆå§‹åŒ–")
            return []
        
        # æŸ¥è¯¢ R-æ ‘
        hits = list(self.rtree_index.intersection(
            (min_x, min_y, max_x, max_y),
            objects=True
        ))
        
        rasters = [hit.object for hit in hits]
        rasters.sort(key=lambda m: m.date if m.date else datetime.min)
        
        logger.debug(f"âœ“ è¾¹ç•Œæ¡† ({min_x}, {min_y}, {max_x}, {max_y}) åŒ…å« {len(rasters)} ä¸ªæ …æ ¼")
        return rasters
    
    def find_rasters_by_date(
        self,
        start_date: Optional[datetime] = None,
        end_date: Optional[datetime] = None,
        year: Optional[int] = None,
        month: Optional[int] = None,
    ) -> List[RasterMetadata]:
        """
        æŒ‰æ—¶é—´æ¡ä»¶æŸ¥æ‰¾æ …æ ¼
        
        Args:
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            year: ç‰¹å®šå¹´ä»½
            month: ç‰¹å®šæœˆä»½
        
        Returns:
            List[RasterMetadata]: ç¬¦åˆæ¡ä»¶çš„æ …æ ¼åˆ—è¡¨
        
        Example:
            >>> # æŸ¥æ‰¾ 2023 å¹´çš„æ‰€æœ‰æ …æ ¼
            >>> rasters = crawler.find_rasters_by_date(year=2023)
            >>> # æŸ¥æ‰¾ 2023 å¹´ 5 æœˆçš„æ …æ ¼
            >>> rasters = crawler.find_rasters_by_date(year=2023, month=5)
        """
        results = []
        
        for metadata in self.raster_list:
            # æ£€æŸ¥å¹´ä»½
            if year is not None:
                if metadata.year != year:
                    continue
            
            # æ£€æŸ¥æœˆä»½
            if month is not None:
                if metadata.month != month:
                    continue
            
            # æ£€æŸ¥æ—¥æœŸèŒƒå›´
            if metadata.date:
                if start_date and metadata.date < start_date:
                    continue
                if end_date and metadata.date > end_date:
                    continue
            
            results.append(metadata)
        
        results.sort(key=lambda m: m.date if m.date else datetime.min)
        return results
    
    def find_rasters_by_filename_pattern(self, pattern: str) -> List[RasterMetadata]:
        """
        æŒ‰æ–‡ä»¶åæ¨¡å¼æŸ¥æ‰¾æ …æ ¼
        
        Args:
            pattern: æ–‡ä»¶åæ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼
        
        Returns:
            List[RasterMetadata]: ç¬¦åˆæ¡ä»¶çš„æ …æ ¼åˆ—è¡¨
        """
        compiled_pattern = re.compile(pattern)
        results = [m for m in self.raster_list if compiled_pattern.match(m.filename)]
        return results
    
    def create_point_index(self, points_df: pd.DataFrame) -> pd.DataFrame:
        """
        ä¸ºç‚¹æ•°æ®é›†æ‰¹é‡å»ºç«‹ä¸æ …æ ¼çš„å…³è”
        
        è¿™æ˜¯ find_rasters_by_point çš„å‘é‡åŒ–ç‰ˆæœ¬ï¼Œé€‚åˆå¤„ç†å¤§é‡ç‚¹
        
        Args:
            points_df: åŒ…å« 'x' å’Œ 'y' åˆ—çš„ DataFrame
        
        Returns:
            pd.DataFrame: åŸ DataFrame åŠ ä¸Š 'raster_files' åˆ—ï¼ˆåˆ—è¡¨ï¼‰
        
        Example:
            >>> points_df['raster_files'] = crawler.create_point_index(points_df)
        """
        logger = logging.getLogger(__name__)
        
        logger.info(f"ğŸ” ä¸º {len(points_df)} ä¸ªç‚¹å»ºç«‹æ …æ ¼å…³è”...")
        
        raster_files_list = []
        for _, row in points_df.iterrows():
            x, y = row['x'], row['y']
            rasters = self.find_rasters_by_point(x, y)
            raster_paths = [str(m.filepath) for m in rasters]
            raster_files_list.append(raster_paths)
        
        logger.info(f"âœ… ç‚¹-æ …æ ¼å…³è”å®Œæˆ")
        
        return raster_files_list
    
    def get_time_series_for_point(
        self,
        x: float,
        y: float,
    ) -> List[RasterMetadata]:
        """
        è·å–æŸä¸ªç‚¹çš„æ—¶é—´åºåˆ—æ …æ ¼
        
        Returns:
            List[RasterMetadata]: æŒ‰æ—¶é—´æ’åºçš„æ …æ ¼åˆ—è¡¨
        """
        return self.find_rasters_by_point(x, y)
    
    def get_statistics(self) -> Dict:
        """
        è·å–çˆ¬è™«ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            Dict: ç»Ÿè®¡ä¿¡æ¯
        """
        if not self.raster_list:
            return {
                'total_rasters': 0,
                'message': 'æœªæ‰¾åˆ°æ …æ ¼æ–‡ä»¶'
            }
        
        dates = [m.date for m in self.raster_list if m.date]
        all_bounds = [m.bounds for m in self.raster_list]
        
        all_lefts = [b[0] for b in all_bounds]
        all_bottoms = [b[1] for b in all_bounds]
        all_rights = [b[2] for b in all_bounds]
        all_tops = [b[3] for b in all_bounds]
        
        crs_counts = {}
        for m in self.raster_list:
            crs_counts[m.crs] = crs_counts.get(m.crs, 0) + 1
        
        year_counts = {}
        for m in self.raster_list:
            if m.year:
                year_counts[m.year] = year_counts.get(m.year, 0) + 1
        
        return {
            'total_rasters': len(self.raster_list),
            'time_coverage': {
                'date_range': (
                    min(dates).isoformat() if dates else None,
                    max(dates).isoformat() if dates else None
                ),
                'unique_dates': len(set([d.date() for d in dates])) if dates else 0,
                'year_distribution': year_counts,
            },
            'spatial_coverage': {
                'bounds': {
                    'min_x': min(all_lefts),
                    'min_y': min(all_bottoms),
                    'max_x': max(all_rights),
                    'max_y': max(all_tops),
                },
                'area': (max(all_rights) - min(all_lefts)) * (max(all_tops) - min(all_bottoms)),
            },
            'crs_distribution': crs_counts,
            'resolution_stats': {
                'min_x_res': min([m.resolution[0] for m in self.raster_list]),
                'max_x_res': max([m.resolution[0] for m in self.raster_list]),
                'min_y_res': min([m.resolution[1] for m in self.raster_list]),
                'max_y_res': max([m.resolution[1] for m in self.raster_list]),
            }
        }
    
    def detect_num_channels(self, sample_size: int = 5) -> Dict[str, int]:
        """
        æ£€æµ‹å½±åƒçš„æ³¢æ®µæ•°
        
        åŠŸèƒ½ï¼šé‡‡æ ·å‡ ä¸ªæ–‡ä»¶å¹¶æ£€æµ‹å…¶æ³¢æ®µæ•°ï¼Œè¿”å›ç»Ÿè®¡ç»“æœ
        
        Args:
            sample_size: é‡‡æ ·çš„æ–‡ä»¶æ•°é‡
        
        Returns:
            Dict: {
                'most_common': int,  # æœ€å¸¸è§çš„æ³¢æ®µæ•°
                'all_channels': {num_channels: count, ...},  # æ³¢æ®µæ•°çš„åˆ†å¸ƒ
                'files_checked': int,  # æ£€æŸ¥çš„æ–‡ä»¶æ•°
                'warning': str (å¦‚æœæ³¢æ®µæ•°ä¸ä¸€è‡´)
            }
        
        Example:
            >>> crawler = RasterCrawler(config)
            >>> result = crawler.detect_num_channels()
            >>> print(f"æœ€å¸¸è§æ³¢æ®µæ•°: {result['most_common']}")
            æœ€å¸¸è§æ³¢æ®µæ•°: 1
        """
        import logging
        logger = logging.getLogger(__name__)
        
        if not self.raster_list:
            logger.warning("âš ï¸  æ— å¯ç”¨çš„æ …æ ¼æ–‡ä»¶")
            return {
                'most_common': 0,
                'all_channels': {},
                'files_checked': 0,
                'warning': 'æ²¡æœ‰æ …æ ¼æ–‡ä»¶'
            }
        
        # é‡‡æ ·æ–‡ä»¶
        sample_files = self.raster_list[:min(sample_size, len(self.raster_list))]
        channel_counts = {}
        
        logger.info(f"ğŸ” æ£€æµ‹æ³¢æ®µæ•°ï¼ˆé‡‡æ · {len(sample_files)}/{len(self.raster_list)} ä¸ªæ–‡ä»¶ï¼‰...")
        
        for metadata in sample_files:
            try:
                with rasterio.open(metadata.filepath) as src:
                    num_channels = src.count
                    channel_counts[num_channels] = channel_counts.get(num_channels, 0) + 1
                    logger.debug(f"   âœ“ {metadata.filename}: {num_channels} ä¸ªæ³¢æ®µ")
            except Exception as e:
                logger.warning(f"   âš ï¸  æ— æ³•è¯»å– {metadata.filename}: {e}")
                continue
        
        if not channel_counts:
            logger.error("âŒ æ— æ³•æ£€æµ‹ä»»ä½•æ–‡ä»¶çš„æ³¢æ®µæ•°")
            return {
                'most_common': 0,
                'all_channels': {},
                'files_checked': len(sample_files),
                'warning': 'æ— æ³•æ£€æµ‹æ³¢æ®µæ•°'
            }
        
        # æ‰¾åˆ°æœ€å¸¸è§çš„æ³¢æ®µæ•°
        most_common = max(channel_counts, key=channel_counts.get)
        
        # æ£€æŸ¥æ˜¯å¦ä¸€è‡´
        warning = None
        if len(channel_counts) > 1:
            warning = f"æ£€æµ‹åˆ°ä¸åŒçš„æ³¢æ®µæ•°: {dict(sorted(channel_counts.items()))}"
            logger.warning(f"âš ï¸  {warning}")
            logger.info(f"   å°†ä½¿ç”¨æœ€å¸¸è§çš„æ³¢æ®µæ•°: {most_common}")
        else:
            logger.info(f"âœ… æ‰€æœ‰é‡‡æ ·æ–‡ä»¶éƒ½æœ‰ {most_common} ä¸ªæ³¢æ®µ")
        
        result = {
            'most_common': most_common,
            'all_channels': dict(sorted(channel_counts.items())),
            'files_checked': len(sample_files),
        }
        
        if warning:
            result['warning'] = warning
        
        return result
    
    def detect_crs(self) -> Dict:
        """
        æ£€æµ‹æ‰€æœ‰å½±åƒçš„åæ ‡å‚è€ƒç³»ç»Ÿ
        
        åŠŸèƒ½ï¼š
        1. æ‰«ææ‰€æœ‰æ …æ ¼çš„ CRS
        2. æ£€æŸ¥æ˜¯å¦ä¸€è‡´
        3. ç”Ÿæˆ CRS æ£€æµ‹æŠ¥å‘Š
        
        Returns:
            Dict: {
                'is_consistent': bool,
                'detected_crs': {crs_code: count, ...},
                'most_common_crs': str,
                'crs_details': {filepath: crs_code},
                'warning': str (å¦‚æœä¸ä¸€è‡´),
                'recommendation': str
            }
        """
        logger = logging.getLogger(__name__)
        
        if not self.raster_list:
            logger.warning("âš ï¸  æ— å¯ç”¨çš„æ …æ ¼æ–‡ä»¶")
            return {
                'is_consistent': True,
                'detected_crs': {},
                'most_common_crs': None,
                'crs_details': {},
                'warning': 'æ²¡æœ‰æ …æ ¼æ–‡ä»¶'
            }
        
        logger.info(f"\nğŸ” æ£€æµ‹åæ ‡å‚è€ƒç³»ç»Ÿï¼ˆCRSï¼‰...")
        logger.info(f"   æ‰«æ {len(self.raster_list)} ä¸ªæ …æ ¼æ–‡ä»¶...")
        
        crs_counts = {}
        crs_details = {}
        
        for metadata in self.raster_list:
            crs = metadata.crs
            crs_counts[crs] = crs_counts.get(crs, 0) + 1
            crs_details[str(metadata.filepath)] = crs
        
        # åˆ¤æ–­ä¸€è‡´æ€§
        is_consistent = len(crs_counts) <= 1
        most_common_crs = max(crs_counts, key=crs_counts.get) if crs_counts else None
        
        # ç”Ÿæˆè­¦å‘Šå’Œå»ºè®®
        warning = None
        recommendation = None
        
        if len(crs_counts) > 1:
            warning = f"æ£€æµ‹åˆ° {len(crs_counts)} ä¸ªä¸åŒçš„åæ ‡ç³»"
            inconsistent_count = sum(count for crs, count in crs_counts.items() if crs != most_common_crs)
            recommendation = (
                f"å°†ä½¿ç”¨æœ€å¸¸è§çš„åæ ‡ç³» {most_common_crs} "
                f"({crs_counts.get(most_common_crs, 0)} ä¸ªæ–‡ä»¶)ã€‚"
                f"å…¶ä»– {inconsistent_count} ä¸ªæ–‡ä»¶å°†è¢«æ ‡è®°ä¸ºä¸ä¸€è‡´ã€‚"
            )
            
            logger.warning(f"âš ï¸  {warning}")
            logger.info(f"âœ… åæ ‡ç³»åˆ†å¸ƒ:")
            for crs, count in sorted(crs_counts.items(), key=lambda x: -x[1]):
                logger.info(f"     - {crs}: {count} ä¸ªæ–‡ä»¶")
        
        elif is_consistent and most_common_crs:
            logger.info(f"âœ… æ‰€æœ‰æ–‡ä»¶ä½¿ç”¨ç›¸åŒçš„åæ ‡ç³»: {most_common_crs}")
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯å¸¸è§æŠ•å½±
        if most_common_crs:
            from crs_manager import CRSManager
            crs_manager = CRSManager(self.config)
            crs_info = crs_manager.get_crs_info(most_common_crs)
            
            if crs_info:
                logger.info(f"   - åç§°: {crs_info.crs_name}")
                logger.info(f"   - ç±»å‹: {'åœ°ç†åæ ‡' if crs_info.is_geographic else 'æŠ•å½±åæ ‡'}")
                logger.info(f"   - å•ä½: {crs_info.units}")
        
        result = {
            'is_consistent': is_consistent,
            'detected_crs': dict(sorted(crs_counts.items())),
            'most_common_crs': most_common_crs,
            'crs_details': crs_details,
        }
        
        if warning:
            result['warning'] = warning
        if recommendation:
            result['recommendation'] = recommendation
        
        return result
    
    def validate_crs_consistency(self, target_crs: Optional[str] = None) -> Dict:
        """
        éªŒè¯ CRS ä¸€è‡´æ€§å¹¶ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
        
        Args:
            target_crs: æœŸæœ›çš„ç›®æ ‡åæ ‡ç³»ï¼ˆå¯é€‰ï¼‰
        
        Returns:
            Dict: éªŒè¯ç»“æœ
        """
        logger = logging.getLogger(__name__)
        
        crs_detection = self.detect_crs()
        
        validation_result = {
            'detection': crs_detection,
            'validation': {
                'is_valid': crs_detection['is_consistent'],
                'issues': [],
                'recommendations': []
            }
        }
        
        # æ£€æŸ¥æ˜¯å¦ä¸ç›®æ ‡ CRS åŒ¹é…
        if target_crs and crs_detection['most_common_crs']:
            if crs_detection['most_common_crs'] != target_crs:
                validation_result['validation']['is_valid'] = False
                issue = (
                    f"å®é™…åæ ‡ç³» ({crs_detection['most_common_crs']}) "
                    f"ä¸ç›®æ ‡åæ ‡ç³» ({target_crs}) ä¸åŒ¹é…"
                )
                validation_result['validation']['issues'].append(issue)
                logger.warning(f"âš ï¸  {issue}")
                
                # å»ºè®®è‡ªåŠ¨é‡æŠ•å½±
                validation_result['validation']['recommendations'].append(
                    "å¯ä»¥é…ç½® auto_reproject: true æ¥è‡ªåŠ¨é‡æŠ•å½±æ–‡ä»¶"
                )
            else:
                logger.info(f"âœ… åæ ‡ç³»ä¸ç›®æ ‡ä¸€è‡´: {target_crs}")
        
        return validation_result
    
    def save_crs_report(self, output_file: Optional[Path] = None) -> Path:
        """
        ä¿å­˜ CRS æ£€æµ‹æŠ¥å‘Šåˆ°æ–‡ä»¶
        
        Args:
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆå¦‚æœä¸º Noneï¼Œåˆ™ä½¿ç”¨é»˜è®¤ä½ç½®ï¼‰
        
        Returns:
            Path: ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
        """
        logger = logging.getLogger(__name__)
        
        if output_file is None:
            output_file = self.output_dir / 'crs_detection_report.json'
        else:
            output_file = Path(output_file)
        
        # ç”ŸæˆæŠ¥å‘Š
        report = {
            'timestamp': datetime.now().isoformat(),
            'raster_dir': str(self.raster_dir),
            'total_rasters': len(self.raster_list),
            'crs_detection': self.detect_crs(),
        }
        
        # ä¿å­˜
        output_file.parent.mkdir(parents=True, exist_ok=True)
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2, default=str)
        
        logger.info(f"ğŸ’¾ CRS æŠ¥å‘Šå·²ä¿å­˜: {output_file}")
        return output_file
    
    def __repr__(self) -> str:
        """å­—ç¬¦ä¸²è¡¨ç¤º"""
        return (
            f"RasterCrawler(\n"
            f"  raster_dir={self.raster_dir},\n"
            f"  total_rasters={len(self.raster_list)},\n"
            f"  output_dir={self.output_dir},\n"
            f"  rtree_indexed=True\n"
            f")"
        )


# ============================================================================
# ä½¿ç”¨ç¤ºä¾‹å’Œæµ‹è¯•
# ============================================================================

if __name__ == "__main__":
    try:
        from config_manager import ConfigManager
        
        print("=" * 80)
        print("RasterCrawler ä½¿ç”¨ç¤ºä¾‹")
        print("=" * 80)
        
        # åˆå§‹åŒ–é…ç½® - è‡ªåŠ¨å®šä½ config.yaml
        config_path = Path(__file__).parent / 'config.yaml'
        config = ConfigManager(str(config_path))
        
        # å®šä¹‰æ–‡ä»¶åæ­£åˆ™è¡¨è¾¾å¼
        # ä¾‹å¦‚æ–‡ä»¶å: GPP230101.tif â†’ æå– year=2023, month=01, day=01
        filename_pattern = r'GPP(?P<year>\d{2})(?P<month>\d{2})(?P<day>\d{2})'
        
        # åˆå§‹åŒ–çˆ¬è™«
        print("\n1ï¸âƒ£  åˆå§‹åŒ– RasterCrawler...")
        crawler = RasterCrawler(
            config=config,
            filename_pattern=filename_pattern
        )
        print(f"\n{crawler}\n")
        
        # è·å–ç»Ÿè®¡ä¿¡æ¯
        print("\n2ï¸âƒ£  è·å–ç»Ÿè®¡ä¿¡æ¯...")
        stats = crawler.get_statistics()
        print(f"âœ… æ …æ ¼ç»Ÿè®¡:")
        print(f"   æ€»æ …æ ¼æ•°: {stats['total_rasters']}")
        if stats.get('time_coverage'):
            print(f"   æ—¶é—´è¦†ç›–: {stats['time_coverage']['date_range']}")
            print(f"   ç‹¬ç«‹æ—¥æœŸæ•°: {stats['time_coverage']['unique_dates']}")
        if stats.get('spatial_coverage'):
            bounds = stats['spatial_coverage']['bounds']
            print(f"   ç©ºé—´èŒƒå›´: ({bounds['min_x']}, {bounds['min_y']}) - ({bounds['max_x']}, {bounds['max_y']})")
        
        # æŸ¥è¯¢ç¤ºä¾‹
        print("\n3ï¸âƒ£  æ …æ ¼æŸ¥è¯¢ç¤ºä¾‹...")
        if stats['total_rasters'] > 0:
            # è·å–æ‰€æœ‰æ …æ ¼
            all_rasters = crawler.get_all_rasters()
            print(f"   æ€»æ …æ ¼: {len(all_rasters)}")
            print(f"   é¦–ä¸ªæ …æ ¼: {all_rasters[0].filename}")
            print(f"   æœ«ä¸ªæ …æ ¼: {all_rasters[-1].filename}")

            # æŒ‰æ—¥æœŸæŸ¥è¯¢
            rasters_2023 = crawler.find_rasters_by_date(year=2023)
            print(f"   2023 å¹´æ …æ ¼: {len(rasters_2023)}")
        
        print("\n" + "=" * 80)
        print("âœ… ç¤ºä¾‹å®Œæˆ!")
        print("=" * 80 + "\n")
        
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
